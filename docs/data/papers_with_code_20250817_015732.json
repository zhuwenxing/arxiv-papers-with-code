[
  {
    "title": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation",
    "authors": "Zhenye Yang, Jinpeng Chen, Huan Li, Xiongnan Jin, Xuanyang Li, Junwei Zhang, Hongbo Gao, Kaimin Wei, Senzhang Wang",
    "published": "2025-08-14",
    "arxiv_id": "2508.10669v1",
    "url": "http://arxiv.org/abs/2508.10669v1",
    "pdf_url": "http://arxiv.org/pdf/2508.10669v1",
    "category": "information_retrieval",
    "primary_category": "cs.AI",
    "abstract": "Conversational recommender systems (CRSs) aim to proactively capture user\npreferences through natural language dialogue and recommend high-quality items.\nTo achieve this, CRS gathers user preferences via a dialog module and builds\nuser profiles through a recommendation module to generate appropriate\nrecommendations. However, existing CRS faces challenges in capturing the deep\nsemantics of user preferences and dialogue context. In particular, the\nefficient integration of external knowledge graph (KG) information into\ndialogue generation and recommendation remains a pressing issue. Traditional\napproaches typically combine KG information directly with dialogue content,\nwhich often struggles with complex semantic relationships, resulting in\nrecommendations that may not align with user expectations.\n  To address these challenges, we introduce STEP, a conversational recommender\ncentered on pre-trained language models that combines curriculum-guided\ncontext-knowledge fusion with lightweight task-specific prompt tuning. At its\nheart, an F-Former progressively aligns the dialogue context with\nknowledge-graph entities through a three-stage curriculum, thus resolving\nfine-grained semantic mismatches. The fused representation is then injected\ninto the frozen language model via two minimal yet adaptive prefix prompts: a\nconversation prefix that steers response generation toward user intent and a\nrecommendation prefix that biases item ranking toward knowledge-consistent\ncandidates. This dual-prompt scheme allows the model to share cross-task\nsemantics while respecting the distinct objectives of dialogue and\nrecommendation. Experimental results show that STEP outperforms mainstream\nmethods in the precision of recommendation and dialogue quality in two public\ndatasets.",
    "code_links": [
      "https://github.com/Alex-bupt/STEP"
    ],
    "comment": "10 pages; 4 figures; 6 tables; code available at\n  https://github.com/Alex-bupt/STEP"
  },
  {
    "title": "FuXi-Î²: Towards a Lightweight and Fast Large-Scale Generative Recommendation Model",
    "authors": "Yufei Ye, Wei Guo, Hao Wang, Hong Zhu, Yuyang Ye, Yong Liu, Huifeng Guo, Ruiming Tang, Defu Lian, Enhong Chen",
    "published": "2025-08-14",
    "arxiv_id": "2508.10615v1",
    "url": "http://arxiv.org/abs/2508.10615v1",
    "pdf_url": "http://arxiv.org/pdf/2508.10615v1",
    "category": "information_retrieval",
    "primary_category": "cs.IR",
    "abstract": "Scaling laws for autoregressive generative recommenders reveal potential for\nlarger, more versatile systems but mean greater latency and training costs. To\naccelerate training and inference, we investigated the recent generative\nrecommendation models HSTU and FuXi-$\\alpha$, identifying two efficiency\nbottlenecks: the indexing operations in relative temporal attention bias and\nthe computation of the query-key attention map. Additionally, we observed that\nrelative attention bias in self-attention mechanisms can also serve as\nattention maps. Previous works like Synthesizer have shown that alternative\nforms of attention maps can achieve similar performance, naturally raising the\nquestion of whether some attention maps are redundant. Through empirical\nexperiments, we discovered that using the query-key attention map might degrade\nthe model's performance in recommendation tasks. To address these bottlenecks,\nwe propose a new framework applicable to Transformer-like recommendation\nmodels. On one hand, we introduce Functional Relative Attention Bias, which\navoids the time-consuming operations of the original relative attention bias,\nthereby accelerating the process. On the other hand, we remove the query-key\nattention map from the original self-attention layer and design a new\nAttention-Free Token Mixer module. Furthermore, by applying this framework to\nFuXi-$\\alpha$, we introduce a new model, FuXi-$\\beta$. Experiments across\nmultiple datasets demonstrate that FuXi-$\\beta$ outperforms previous\nstate-of-the-art models and achieves significant acceleration compared to\nFuXi-$\\alpha$, while also adhering to the scaling law. Notably, FuXi-$\\beta$\nshows an improvement of 27% to 47% in the NDCG@10 metric on large-scale\nindustrial datasets compared to FuXi-$\\alpha$. Our code is available in a\npublic repository: https://github.com/USTC-StarTeam/FuXi-beta",
    "code_links": [
      "https://github.com/USTC-StarTeam/FuXi-beta"
    ],
    "comment": null
  },
  {
    "title": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers",
    "authors": "Hanna Herasimchyk, Robin Labryga, Tomislav Prusina",
    "published": "2025-08-14",
    "arxiv_id": "2508.10457v1",
    "url": "http://arxiv.org/abs/2508.10457v1",
    "pdf_url": "http://arxiv.org/pdf/2508.10457v1",
    "category": "information_retrieval",
    "primary_category": "cs.CV",
    "abstract": "We present a multi-head vision transformer approach for multi-label plant\nspecies prediction in vegetation plot images, addressing the PlantCLEF 2025\nchallenge. The task involves training models on single-species plant images\nwhile testing on multi-species quadrat images, creating a drastic domain shift.\nOur methodology leverages a pre-trained DINOv2 Vision Transformer Base\n(ViT-B/14) backbone with multiple classification heads for species, genus, and\nfamily prediction, utilizing taxonomic hierarchies. Key contributions include\nmulti-scale tiling to capture plants at different scales, dynamic threshold\noptimization based on mean prediction length, and ensemble strategies through\nbagging and Hydra model architectures. The approach incorporates various\ninference techniques including image cropping to remove non-plant artifacts,\ntop-n filtering for prediction constraints, and logit thresholding strategies.\nExperiments were conducted on approximately 1.4 million training images\ncovering 7,806 plant species. Results demonstrate strong performance, making\nour submission 3rd best on the private leaderboard. Our code is available at\nhttps://github.com/geranium12/plant-clef-2025/tree/v1.0.0.",
    "code_links": [
      "https://github.com/geranium12/plant-clef-2025"
    ],
    "comment": "Accepted for publication at: LifeCLEF Lab at CLEF 2025 Working Notes,\n  2025, Madrid, Spain"
  },
  {
    "title": "TFRank: Think-Free Reasoning Enables Practical Pointwise LLM Ranking",
    "authors": "Yongqi Fan, Xiaoyang Chen, Dezhi Ye, Jie Liu, Haijin Liang, Jin Ma, Ben He, Yingfei Sun, Tong Ruan",
    "published": "2025-08-13",
    "arxiv_id": "2508.09539v1",
    "url": "http://arxiv.org/abs/2508.09539v1",
    "pdf_url": "http://arxiv.org/pdf/2508.09539v1",
    "category": "information_retrieval",
    "primary_category": "cs.IR",
    "abstract": "Reasoning-intensive ranking models built on Large Language Models (LLMs) have\nmade notable progress, but existing approaches often rely on large-scale LLMs\nand explicit Chain-of-Thought (CoT) reasoning, resulting in high computational\ncost and latency that limit real-world use. To address this, we propose\n\\textbf{TFRank}, an efficient pointwise reasoning ranker based on small-scale\nLLMs. To improve ranking performance, TFRank effectively integrates CoT data,\nfine-grained score supervision, and multi-task training. Furthermore, it\nachieves an efficient ``\\textbf{T}hink-\\textbf{F}ree\" reasoning capability by\nemploying a ``think-mode switch'' and pointwise format constraints.\nSpecifically, this allows the model to leverage explicit reasoning during\ntraining while delivering precise relevance scores for complex queries at\ninference without generating any reasoning chains. Experiments show that TFRank\n(e.g., 1.7B) achieves performance comparable to models with four times more\nparameters on the BRIGHT benchmark, and demonstrates strong competitiveness on\nthe BEIR benchmark. Further analysis shows that TFRank achieves an effective\nbalance between performance and efficiency, providing a practical solution for\nintegrating advanced reasoning into real-world systems. Our code and data are\nreleased in the repository: https://github.com/JOHNNY-fans/TFRank.",
    "code_links": [
      "https://github.com/JOHNNY-fans/TFRank"
    ],
    "comment": null
  },
  {
    "title": "A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition",
    "authors": "Md Rezwanul Haque, Md. Milon Islam, S M Taslim Uddin Raju, Fakhri Karray",
    "published": "2025-08-12",
    "arxiv_id": "2508.09372v1",
    "url": "http://arxiv.org/abs/2508.09372v1",
    "pdf_url": "http://arxiv.org/pdf/2508.09372v1",
    "category": "information_retrieval",
    "primary_category": "cs.CV",
    "abstract": "Continuous Sign Language Recognition (CSLR) faces multiple challenges,\nincluding significant inter-signer variability and poor generalization to novel\nsentence structures. Traditional solutions frequently fail to handle these\nissues efficiently. For overcoming these constraints, we propose a\ndual-architecture framework. For the Signer-Independent (SI) challenge, we\npropose a Signer-Invariant Conformer that combines convolutions with multi-head\nself-attention to learn robust, signer-agnostic representations from pose-based\nskeletal keypoints. For the Unseen-Sentences (US) task, we designed a\nMulti-Scale Fusion Transformer with a novel dual-path temporal encoder that\ncaptures both fine-grained posture dynamics, enabling the model's ability to\ncomprehend novel grammatical compositions. Experiments on the challenging\nIsharah-1000 dataset establish a new standard for both CSLR benchmarks. The\nproposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on\nthe SI challenge, a reduction of 13.53% from the state-of-the-art. On the US\ntask, the transformer model scores a WER of 47.78%, surpassing previous work.\nIn the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th\nin the SI task, demonstrating the performance of these models. The findings\nvalidate our key hypothesis: that developing task-specific networks designed\nfor the particular challenges of CSLR leads to considerable performance\nimprovements and establishes a new baseline for further research. The source\ncode is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.",
    "code_links": [
      "https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah"
    ],
    "comment": "Accepted for the IEEE/CVF International Conference on Computer Vision\n  (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025"
  },
  {
    "title": "HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches",
    "authors": "Jiejun Tan, Zhicheng Dou, Yan Yu, Jiehan Cheng, Qiang Ju, Jian Xie, Ji-Rong Wen",
    "published": "2025-08-11",
    "arxiv_id": "2508.08088v1",
    "url": "http://arxiv.org/abs/2508.08088v1",
    "pdf_url": "http://arxiv.org/pdf/2508.08088v1",
    "category": "information_retrieval",
    "primary_category": "cs.IR",
    "abstract": "Recently, large reasoning models have demonstrated strong mathematical and\ncoding abilities, and deep search leverages their reasoning capabilities in\nchallenging information retrieval tasks. Existing deep search works are\ngenerally limited to a single knowledge source, either local or the Web.\nHowever, enterprises often require private deep search systems that can\nleverage search tools over both local and the Web corpus. Simply training an\nagent equipped with multiple search tools using flat reinforcement learning\n(RL) is a straightforward idea, but it has problems such as low training data\nefficiency and poor mastery of complex tools. To address the above issue, we\npropose a hierarchical agentic deep search framework, HierSearch, trained with\nhierarchical RL. At the low level, a local deep search agent and a Web deep\nsearch agent are trained to retrieve evidence from their corresponding domains.\nAt the high level, a planner agent coordinates low-level agents and provides\nthe final answer. Moreover, to prevent direct answer copying and error\npropagation, we design a knowledge refiner that filters out hallucinations and\nirrelevant evidence returned by low-level agents. Experiments show that\nHierSearch achieves better performance compared to flat RL, and outperforms\nvarious deep search and multi-source retrieval-augmented generation baselines\nin six benchmarks across general, finance, and medical domains.",
    "code_links": [
      "https://github.com/plageon/HierSearch"
    ],
    "comment": "Code and datasets are available at\n  https://github.com/plageon/HierSearch"
  },
  {
    "title": "Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation",
    "authors": "Van-Khang Nguyen, Duc-Hoang Pham, Huy-Son Nguyen, Cam-Van Thi Nguyen, Hoang-Quynh Le, Duc-Trong Le",
    "published": "2025-08-11",
    "arxiv_id": "2508.08042v1",
    "url": "http://arxiv.org/abs/2508.08042v1",
    "pdf_url": "http://arxiv.org/pdf/2508.08042v1",
    "category": "information_retrieval",
    "primary_category": "cs.IR",
    "abstract": "Recommendation systems have faced significant challenges in cold-start\nscenarios, where new items with a limited history of interaction need to be\neffectively recommended to users. Though multimodal data (e.g., images, text,\naudio, etc.) offer rich information to address this issue, existing approaches\noften employ simplistic integration methods such as concatenation, average\npooling, or fixed weighting schemes, which fail to capture the complex\nrelationships between modalities. Our study proposes a novel Mixture of Experts\n(MoE) framework for multimodal cold-start recommendation, named MAMEX, which\ndynamically leverages latent representation from different modalities. MAMEX\nutilizes modality-specific expert networks and introduces a learnable gating\nmechanism that adaptively weights the contribution of each modality based on\nits content characteristics. This approach enables MAMEX to emphasize the most\ninformative modalities for each item while maintaining robustness when certain\nmodalities are less relevant or missing. Extensive experiments on benchmark\ndatasets show that MAMEX outperforms state-of-the-art methods in cold-start\nscenarios, with superior accuracy and adaptability. For reproducibility, the\ncode has been made available on Github https://github.com/L2R-UET/MAMEX.",
    "code_links": [
      "https://github.com/L2R-UET/MAMEX"
    ],
    "comment": null
  },
  {
    "title": "Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking",
    "authors": "Jian Chen, Jinbao Tian, Yankui Li, Zhou Li",
    "published": "2025-08-10",
    "arxiv_id": "2508.07286v1",
    "url": "http://arxiv.org/abs/2508.07286v1",
    "pdf_url": "http://arxiv.org/pdf/2508.07286v1",
    "category": "information_retrieval",
    "primary_category": "cs.CL",
    "abstract": "Accurate information extraction from specialized texts is a critical\nchallenge, particularly for named entity recognition (NER) in the architecture,\nengineering, and construction (AEC) domain to support automated rule checking\n(ARC). The performance of standard pre-trained models is often constrained by\nthe domain gap, as they struggle to interpret the specialized terminology and\ncomplex relational contexts inherent in AEC texts. Although this issue can be\nmitigated by further pre-training on large, human-curated domain corpora, as\nexemplified by methods like ARCBERT, this approach is both labor-intensive and\ncost-prohibitive. Consequently, leveraging large language models (LLMs) for\nautomated knowledge generation has emerged as a promising alternative. However,\nthe optimal strategy for generating knowledge that can genuinely enhance\nsmaller, efficient models remains an open question. To address this, we propose\nARCE (augmented RoBERTa with contextualized elucidations), a novel approach\nthat systematically explores and optimizes this generation process. ARCE\nemploys an LLM to first generate a corpus of simple, direct explanations, which\nwe term Cote, and then uses this corpus to incrementally pre-train a RoBERTa\nmodel prior to its fine-tuning on the downstream task. Our extensive\nexperiments show that ARCE establishes a new state-of-the-art on a benchmark\nAEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a\nkey finding: simple, explanation-based knowledge proves surprisingly more\neffective than complex, role-based rationales for this task. The code is\npublicly available at:https://github.com/nxcc-lab/ARCE.",
    "code_links": [
      "https://github.com/nxcc-lab/ARCE"
    ],
    "comment": null
  },
  {
    "title": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability",
    "authors": "Wenhan Liu, Xinyu Ma, Weiwei Sun, Yutao Zhu, Yuchen Li, Dawei Yin, Zhicheng Dou",
    "published": "2025-08-09",
    "arxiv_id": "2508.07050v1",
    "url": "http://arxiv.org/abs/2508.07050v1",
    "pdf_url": "http://arxiv.org/pdf/2508.07050v1",
    "category": "information_retrieval",
    "primary_category": "cs.IR",
    "abstract": "Large Language Model (LLM) based listwise ranking has shown superior\nperformance in many passage ranking tasks. With the development of Large\nReasoning Models, many studies have demonstrated that step-by-step reasoning\nduring test-time helps improve listwise ranking performance. However, due to\nthe scarcity of reasoning-intensive training data, existing rerankers perform\npoorly in many complex ranking scenarios and the ranking ability of\nreasoning-intensive rerankers remains largely underdeveloped. In this paper, we\nfirst propose an automated reasoning-intensive training data synthesis\nframework, which sources training queries and passages from diverse domains and\napplies DeepSeek-R1 to generate high-quality training labels. A\nself-consistency data filtering mechanism is designed to ensure the data\nquality. To empower the listwise reranker with strong reasoning ability, we\nfurther propose a two-stage post-training approach, which includes a cold-start\nsupervised fine-tuning (SFT) stage for reasoning pattern learning and a\nreinforcement learning (RL) stage for further ranking ability enhancement.\nDuring the RL stage, based on the nature of listwise ranking, we design a\nmulti-view ranking reward, which is more effective than a ranking metric-based\nreward. Extensive experiments demonstrate that our trained reasoning-intensive\nreranker \\textbf{ReasonRank} outperforms existing baselines significantly and\nalso achieves much lower latency than pointwise reranker Rank1. \\textbf{Through\nfurther experiments, our ReasonRank has achieved state-of-the-art (SOTA)\nperformance 40.6 on the BRIGHT\nleaderboard\\footnote{https://brightbenchmark.github.io/}.} Our codes are\navailable at https://github.com/8421BCD/ReasonRank.",
    "code_links": [
      "https://github.com/8421BCD/ReasonRank"
    ],
    "comment": "21 pages"
  },
  {
    "title": "eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion",
    "authors": "Daria Tikhonovich, Nikita Zelinskiy, Aleksandr V. Petrov, Mayya Spirina, Andrei Semenov, Andrey V. Savchenko, Sergei Kuliev",
    "published": "2025-08-08",
    "arxiv_id": "2508.06450v1",
    "url": "http://arxiv.org/abs/2508.06450v1",
    "pdf_url": "http://arxiv.org/pdf/2508.06450v1",
    "category": "information_retrieval",
    "primary_category": "cs.IR",
    "abstract": "Since their introduction, Transformer-based models, such as SASRec and\nBERT4Rec, have become common baselines for sequential recommendations,\nsurpassing earlier neural and non-neural methods. A number of following\npublications have shown that the effectiveness of these models can be improved\nby, for example, slightly updating the architecture of the Transformer layers,\nusing better training objectives, and employing improved loss functions.\nHowever, the additivity of these modular improvements has not been\nsystematically benchmarked - this is the gap we aim to close in this paper.\nThrough our experiments, we identify a very strong model that uses SASRec's\ntraining objective, LiGR Transformer layers, and Sampled Softmax Loss. We call\nthis combination eSASRec (Enhanced SASRec). While we primarily focus on\nrealistic, production-like evaluation, in our preliminarily study we find that\ncommon academic benchmarks show eSASRec to be 23% more effective compared to\nthe most recent state-of-the-art models, such as ActionPiece. In our main\nproduction-like benchmark, eSASRec resides on the Pareto frontier in terms of\nthe accuracy-coverage tradeoff (alongside the recent industrial models HSTU and\nFuXi. As the modifications compared to the original SASRec are relatively\nstraightforward and no extra features are needed (such as timestamps in HSTU),\nwe believe that eSASRec can be easily integrated into existing recommendation\npipelines and can can serve as a strong yet very simple baseline for emerging\ncomplicated algorithms. To facilitate this, we provide the open-source\nimplementations for our models and benchmarks in repository\nhttps://github.com/blondered/transformer_benchmark",
    "code_links": [
      "https://github.com/blondered/transformer_benchmark"
    ],
    "comment": "Accepted at ACM RecSys 2025"
  },
  {
    "title": "Balancing Accuracy and Novelty with Sub-Item Popularity",
    "authors": "Chiara Mallamaci, Aleksandr Vladimirovich Petrov, Alberto Carlo Maria Mancino, Vito Walter Anelli, Tommaso Di Noia, Craig Macdonald",
    "published": "2025-08-07",
    "arxiv_id": "2508.05198v1",
    "url": "http://arxiv.org/abs/2508.05198v1",
    "pdf_url": "http://arxiv.org/pdf/2508.05198v1",
    "category": "information_retrieval",
    "primary_category": "cs.IR",
    "abstract": "In the realm of music recommendation, sequential recommenders have shown\npromise in capturing the dynamic nature of music consumption. A key\ncharacteristic of this domain is repetitive listening, where users frequently\nreplay familiar tracks. To capture these repetition patterns, recent research\nhas introduced Personalised Popularity Scores (PPS), which quantify\nuser-specific preferences based on historical frequency. While PPS enhances\nrelevance in recommendation, it often reinforces already-known content,\nlimiting the system's ability to surface novel or serendipitous items - key\nelements for fostering long-term user engagement and satisfaction. To address\nthis limitation, we build upon RecJPQ, a Transformer-based framework initially\ndeveloped to improve scalability in large-item catalogues through sub-item\ndecomposition. We repurpose RecJPQ's sub-item architecture to model\npersonalised popularity at a finer granularity. This allows us to capture\nshared repetition patterns across sub-embeddings - latent structures not\naccessible through item-level popularity alone. We propose a novel integration\nof sub-ID-level personalised popularity within the RecJPQ framework, enabling\nexplicit control over the trade-off between accuracy and personalised novelty.\nOur sub-ID-level PPS method (sPPS) consistently outperforms item-level PPS by\nachieving significantly higher personalised novelty without compromising\nrecommendation accuracy. Code and experiments are publicly available at\nhttps://github.com/sisinflab/Sub-id-Popularity.",
    "code_links": [
      "https://github.com/sisinflab/Sub-id-Popularity"
    ],
    "comment": null
  },
  {
    "title": "Synthesize, Retrieve, and Propagate: A Unified Predictive Modeling Framework for Relational Databases",
    "authors": "Ning Li, Kounianhua Du, Han Zhang, Quan Gan, Minjie Wang, David Wipf, Weinan Zhang",
    "published": "2025-08-10",
    "arxiv_id": "2508.08327v1",
    "url": "http://arxiv.org/abs/2508.08327v1",
    "pdf_url": "http://arxiv.org/pdf/2508.08327v1",
    "category": "databases",
    "primary_category": "cs.DB",
    "abstract": "Relational databases (RDBs) have become the industry standard for storing\nmassive and heterogeneous data. However, despite the widespread use of RDBs\nacross various fields, the inherent structure of relational databases hinders\ntheir ability to benefit from flourishing deep learning methods. Previous\nresearch has primarily focused on exploiting the unary dependency among\nmultiple tables in a relational database using the primary key - foreign key\nrelationships, either joining multiple tables into a single table or\nconstructing a graph among them, which leaves the implicit composite relations\namong different tables and a substantial potential of improvement for\npredictive modeling unexplored. In this paper, we propose SRP, a unified\npredictive modeling framework that synthesizes features using the unary\ndependency, retrieves related information to capture the composite dependency,\nand propagates messages across a constructed graph to learn adjacent patterns\nfor prediction on relation databases. By introducing a new retrieval mechanism\ninto RDB, SRP is designed to fully capture both the unary and the composite\ndependencies within a relational database, thereby enhancing the receptive\nfield of tabular data prediction. In addition, we conduct a comprehensive\nanalysis on the components of SRP, offering a nuanced understanding of model\nbehaviors and practical guidelines for future applications. Extensive\nexperiments on five real-world datasets demonstrate the effectiveness of SRP\nand its potential applicability in industrial scenarios. The code is released\nat https://github.com/NingLi670/SRP.",
    "code_links": [
      "https://github.com/NingLi670/SRP"
    ],
    "comment": null
  },
  {
    "title": "CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search",
    "authors": "Xiaoya Li, Xiaofei Sun, Albert Wang, Chris Shum, Jiwei Li",
    "published": "2025-08-04",
    "arxiv_id": "2508.02091v1",
    "url": "http://arxiv.org/abs/2508.02091v1",
    "pdf_url": "http://arxiv.org/pdf/2508.02091v1",
    "category": "databases",
    "primary_category": "cs.LG",
    "abstract": "Approximate nearest-neighbor search (ANNS) algorithms have become\nincreasingly critical for recent AI applications, particularly in\nretrieval-augmented generation (RAG) and agent-based LLM applications. In this\npaper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS\noptimization as a reinforcement learning problem where execution speed serves\nas the reward signal. This approach enables the automatic generation of\nprogressively faster ANNS implementations while maintaining accuracy\nconstraints. Our experimental evaluation demonstrates CRINN's effectiveness\nacross six widely-used NNS benchmark datasets. When compared against\nstate-of-the-art open-source ANNS algorithms, CRINN achieves best performance\non three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and\nGloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean\nand GloVe-25-angular). The implications of CRINN's success reach well beyond\nANNS optimization: It validates that LLMs augmented with reinforcement learning\ncan function as an effective tool for automating sophisticated algorithmic\noptimizations that demand specialized knowledge and labor-intensive manual\nrefinement.Code can be found at https://github.com/deepreinforce-ai/CRINN",
    "code_links": [
      "https://github.com/deepreinforce-ai/CRINN"
    ],
    "comment": "Preprint Version"
  },
  {
    "title": "DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs",
    "authors": "Wei Zhou, Peng Sun, Xuanhe Zhou, Qianglei Zang, Ji Xu, Tieying Zhang, Guoliang Li, Fan Wu",
    "published": "2025-08-02",
    "arxiv_id": "2508.01136v1",
    "url": "http://arxiv.org/abs/2508.01136v1",
    "pdf_url": "http://arxiv.org/pdf/2508.01136v1",
    "category": "databases",
    "primary_category": "cs.DB",
    "abstract": "The operation and maintenance (O&M) of database systems is critical to\nensuring system availability and performance, typically requiring expert\nexperience (e.g., identifying metric-to-anomaly relations) for effective\ndiagnosis and recovery. However, existing automatic database O&M methods,\nincluding commercial products, cannot effectively utilize expert experience. On\nthe one hand, rule-based methods only support basic O&M tasks (e.g.,\nmetric-based anomaly detection), which are mostly numerical equations and\ncannot effectively incorporate literal O&M experience (e.g., troubleshooting\nguidance in manuals). On the other hand, LLM-based methods, which retrieve\nfragmented information (e.g., standard documents + RAG), often generate\ninaccurate or generic results. To address these limitations, we present\nDBAIOps, a novel hybrid database O&M system that combines reasoning LLMs with\nknowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a\nheterogeneous graph model for representing the diagnosis experience, and\nproposes a semi-automatic graph construction algorithm to build that graph from\nthousands of documents. Second, DBAIOps develops a collection of (800+)\nreusable anomaly models that identify both directly alerted metrics and\nimplicitly correlated experience and metrics. Third, for each anomaly, DBAIOps\nproposes a two-stage graph evolution mechanism to explore relevant diagnosis\npaths and identify missing relations automatically. It then leverages a\nreasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear\ndiagnosis reports for both DBAs and common users. Our evaluation over four\nmainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates\nthat DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher\nin root cause and human evaluation accuracy, respectively.",
    "code_links": [
      "https://github.com/weAIDB/DBAIOps"
    ],
    "comment": "DBAIOps supports 25 database systems and has been deployed in 20\n  real-world scenarios, covering domains like finance, energy, and healthcare.\n  See website at: https://www.dbaiops.com; See code at:\n  https://github.com/weAIDB/DBAIOps/"
  },
  {
    "title": "StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation",
    "authors": "Satyananda Kashyap, Sola Shirai, Nandana Mihindukulasooriya, Horst Samulowitz",
    "published": "2025-07-28",
    "arxiv_id": "2507.21340v1",
    "url": "http://arxiv.org/abs/2507.21340v1",
    "pdf_url": "http://arxiv.org/pdf/2507.21340v1",
    "category": "databases",
    "primary_category": "cs.CL",
    "abstract": "Extracting structured information from text, such as key-value pairs that\ncould augment tabular data, is quite useful in many enterprise use cases.\nAlthough large language models (LLMs) have enabled numerous automated pipelines\nfor converting natural language into structured formats, there is still a lack\nof benchmarks for evaluating their extraction quality, especially in specific\ndomains or focused documents specific to a given organization. Building such\nbenchmarks by manual annotations is labour-intensive and limits the size and\nscalability of the benchmarks. In this work, we present StructText, an\nend-to-end framework for automatically generating high-fidelity benchmarks for\nkey-value extraction from text using existing tabular data. It uses available\ntabular data as structured ground truth, and follows a two-stage\n``plan-then-execute'' pipeline to synthetically generate corresponding\nnatural-language text. To ensure alignment between text and structured source,\nwe introduce a multi-dimensional evaluation strategy that combines (a)\nLLM-based judgments on factuality, hallucination, and coherence and (b)\nobjective extraction metrics measuring numeric and temporal accuracy. We\nevaluated the proposed method on 71,539 examples across 49 datasets. Results\nreveal that while LLMs achieve strong factual accuracy and avoid hallucination,\nthey struggle with narrative coherence in producing extractable text. Notably,\nmodels presume numerical and temporal information with high fidelity yet this\ninformation becomes embedded in narratives that resist automated extraction. We\nrelease a framework, including datasets, evaluation tools, and baseline\nextraction systems, to support continued research.",
    "code_links": [
      "https://github.com/ibm/struct-text"
    ],
    "comment": "Data available:\n  https://huggingface.co/datasets/ibm-research/struct-text and code available\n  at: https://github.com/ibm/struct-text"
  },
  {
    "title": "MH-GIN: Multi-scale Heterogeneous Graph-based Imputation Network for AIS Data (Extended Version)",
    "authors": "Hengyu Liu, Tianyi Li, Yuqiang He, Kristian Torp, Yushuai Li, Christian S. Jensen",
    "published": "2025-07-27",
    "arxiv_id": "2507.20362v1",
    "url": "http://arxiv.org/abs/2507.20362v1",
    "pdf_url": "http://arxiv.org/pdf/2507.20362v1",
    "category": "databases",
    "primary_category": "cs.LG",
    "abstract": "Location-tracking data from the Automatic Identification System, much of\nwhich is publicly available, plays a key role in a range of maritime safety and\nmonitoring applications. However, the data suffers from missing values that\nhamper downstream applications. Imputing the missing values is challenging\nbecause the values of different heterogeneous attributes are updated at diverse\nrates, resulting in the occurrence of multi-scale dependencies among\nattributes. Existing imputation methods that assume similar update rates across\nattributes are unable to capture and exploit such dependencies, limiting their\nimputation accuracy. We propose MH-GIN, a Multi-scale Heterogeneous Graph-based\nImputation Network that aims improve imputation accuracy by capturing\nmulti-scale dependencies. Specifically, MH-GIN first extracts multi-scale\ntemporal features for each attribute while preserving their intrinsic\nheterogeneous characteristics. Then, it constructs a multi-scale heterogeneous\ngraph to explicitly model dependencies between heterogeneous attributes to\nenable more accurate imputation of missing values through graph propagation.\nExperimental results on two real-world datasets find that MH-GIN is capable of\nan average 57% reduction in imputation errors compared to state-of-the-art\nmethods, while maintaining computational efficiency. The source code and\nimplementation details of MH-GIN are publicly available\nhttps://github.com/hyLiu1994/MH-GIN.",
    "code_links": [
      "https://github.com/hyLiu1994/MH-GIN"
    ],
    "comment": "18 pages, 4 figures"
  }
]