title,authors,published,arxiv_id,url,pdf_url,category,primary_category,abstract,code_links,comment
Upcycling Candidate Tokens of Large Language Models for Query Expansion,"Jinseok Kim, Sukmin Cho, Soyeong Jeong, Sangyeop Kim, Sungzoon Cho",2025-09-02,2509.02377v1,http://arxiv.org/abs/2509.02377v1,http://arxiv.org/pdf/2509.02377v1,information_retrieval,cs.IR,"Query Expansion (QE) improves retrieval performance by enriching queries with
related terms. Recently, Large Language Models (LLMs) have been used for QE,
but existing methods face a trade-off: generating diverse terms boosts
performance but increases computational cost. To address this challenge, we
propose Candidate Token Query Expansion (CTQE), which extracts diverse and
relevant terms from a single LLM decoding pass by leveraging unselected
candidate tokens. These tokens, though not part of the final output, are
conditioned on the full query and capture useful information. By aggregating
them, CTQE achieves both relevance and diversity without extra inference,
reducing overhead and latency. Experiments show that CTQE delivers strong
retrieval performance with significantly lower cost, outperforming or
comparable to more expensive methods. Code is available at:
https://github.com/bluejeans8/CTQE",https://github.com/bluejeans8/CTQE,CIKM 2025
Abex-rat: Synergizing Abstractive Augmentation and Adversarial Training for Classification of Occupational Accident Reports,"Jian Chen, Jinbao Tian, Yunqi Xu, Zhou Li",2025-09-02,2509.02072v1,http://arxiv.org/abs/2509.02072v1,http://arxiv.org/pdf/2509.02072v1,information_retrieval,cs.LG,"The automatic classification of occupational accident reports is a critical
research area for enhancing workplace safety and enabling large-scale risk
analysis. However, the severe class imbalance inherent in these real-world
datasets often compromises the performance of analytical models, particularly
for rare but severe incident types, hindering the development of reliable
automated systems. To address this challenge, we propose ABEX-RAT, a novel and
efficient framework that synergizes generative data augmentation with robust
adversarial training. Our approach first employs a twostep
abstractive-expansive (ABEX) pipeline, which leverages a large language model
to distill core incident semantics and then uses a generative model to create
diverse, highquality synthetic samples for underrepresented classes.
Subsequently, a lightweight classifier is trained on the augmented data using a
computationally efficient random adversarial training (RAT) protocol, which
stochastically applies perturbations to enhance model generalization and
robustness without significant overhead. Experimental results on the public
OSHA dataset demonstrate that our method achieves new state-of-the-art
performance, reaching a macro-F1 score of 90.32% and significantly
outperforming previous SOTA and fine-tuned large model baselines. Our work
validates that this synergistic strategy is a highly effective and efficient
alternative to brute-force fine-tuning for specialized, imbalanced
classification tasks. The code is publicly available
at:https://github.com/nxcc-lab/ABEX-RAT.",https://github.com/nxcc-lab/ABEX-RAT,
Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs,"Yuhao Wang, Junwei Pan, Xinhang Li, Maolin Wang, Yuan Wang, Yue Liu, Dapeng Liu, Jie Jiang, Xiangyu Zhao",2025-09-02,2509.02017v1,http://arxiv.org/abs/2509.02017v1,http://arxiv.org/pdf/2509.02017v1,information_retrieval,cs.IR,"Sequential recommendation (SR) aims to capture users' dynamic interests and
sequential patterns based on their historical interactions. Recently, the
powerful capabilities of large language models (LLMs) have driven their
adoption in SR. However, we identify two critical challenges in existing
LLM-based SR methods: 1) embedding collapse when incorporating pre-trained
collaborative embeddings and 2) catastrophic forgetting of quantized embeddings
when utilizing semantic IDs. These issues dampen the model scalability and lead
to suboptimal recommendation performance. Therefore, based on LLMs like
Llama3-8B-instruct, we introduce a novel SR framework named MME-SID, which
integrates multimodal embeddings and quantized embeddings to mitigate embedding
collapse. Additionally, we propose a Multimodal Residual Quantized Variational
Autoencoder (MM-RQ-VAE) with maximum mean discrepancy as the reconstruction
loss and contrastive learning for alignment, which effectively preserve
intra-modal distance information and capture inter-modal correlations,
respectively. To further alleviate catastrophic forgetting, we initialize the
model with the trained multimodal code embeddings. Finally, we fine-tune the
LLM efficiently using LoRA in a multimodal frequency-aware fusion manner.
Extensive experiments on three public datasets validate the superior
performance of MME-SID thanks to its capability to mitigate embedding collapse
and catastrophic forgetting. The implementation code and datasets are publicly
available for reproduction:
https://github.com/Applied-Machine-Learning-Lab/MME-SID.",https://github.com/Applied-Machine-Learning-Lab/MME-SID,CIKM 2025 Full Research Paper
MARS: Modality-Aligned Retrieval for Sequence Augmented CTR Prediction,"Yutian Xiao, Shukuan Wang, Binhao Wang, Zhao Zhang, Yanze Zhang, Shanqi Liu, Chao Feng, Xiang Li, Fuzhen Zhuang",2025-09-01,2509.01184v1,http://arxiv.org/abs/2509.01184v1,http://arxiv.org/pdf/2509.01184v1,information_retrieval,cs.IR,"Click-through rate (CTR) prediction serves as a cornerstone of recommender
systems. Despite the strong performance of current CTR models based on user
behavior modeling, they are still severely limited by interaction sparsity,
especially in low-active user scenarios. To address this issue, data
augmentation of user behavior is a promising research direction. However,
existing data augmentation methods heavily rely on collaborative signals while
overlooking the rich multimodal features of items, leading to insufficient
modeling of low-active users.
  To alleviate this problem, we propose a novel framework \textbf{MARS}
(\textbf{M}odality-\textbf{A}ligned \textbf{R}etrieval for \textbf{S}equence
Augmented CTR Prediction). MARS utilizes a Stein kernel-based approach to align
text and image features into a unified and unbiased semantic space to construct
multimodal user embeddings. Subsequently, each low-active user's behavior
sequence is augmented by retrieving, filtering, and concentrating the most
similar behavior sequence of high-active users via multimodal user embeddings.
Validated by extensive offline experiments and online A/B tests, our framework
MARS consistently outperforms state-of-the-art baselines and achieves
substantial growth on core business metrics within
Kuaishou~\footnote{https://www.kuaishou.com/}. Consequently, MARS has been
successfully deployed, serving the main traffic for hundreds of millions of
users. To ensure reproducibility, we provide anonymous access to the
implementation code~\footnote{https://github.com/wangshukuan/MARS}.",https://github.com/wangshukuan/MARS,
BALM-TSF: Balanced Multimodal Alignment for LLM-Based Time Series Forecasting,"Shiqiao Zhou, Holger Schöner, Huanbo Lyu, Edouard Fouché, Shuo Wang",2025-08-30,2509.00622v1,http://arxiv.org/abs/2509.00622v1,http://arxiv.org/pdf/2509.00622v1,information_retrieval,cs.AI,"Time series forecasting is a long-standing and highly challenging research
topic. Recently, driven by the rise of large language models (LLMs), research
has increasingly shifted from purely time series methods toward harnessing
textual modalities to enhance forecasting performance. However, the vast
discrepancy between text and temporal data often leads current multimodal
architectures to over-emphasise one modality while neglecting the other,
resulting in information loss that harms forecasting performance. To address
this modality imbalance, we introduce BALM-TSF (Balanced Multimodal Alignment
for LLM-Based Time Series Forecasting), a lightweight time series forecasting
framework that maintains balance between the two modalities. Specifically, raw
time series are processed by the time series encoder, while descriptive
statistics of raw time series are fed to an LLM with learnable prompt,
producing compact textual embeddings. To ensure balanced cross-modal context
alignment of time series and textual embeddings, a simple yet effective scaling
strategy combined with a contrastive objective then maps these textual
embeddings into the latent space of the time series embeddings. Finally, the
aligned textual semantic embeddings and time series embeddings are together
integrated for forecasting. Extensive experiments on standard benchmarks show
that, with minimal trainable parameters, BALM-TSF achieves state-of-the-art
performance in both long-term and few-shot forecasting, confirming its ability
to harness complementary information from text and time series. Code is
available at https://github.com/ShiqiaoZhou/BALM-TSF.",https://github.com/ShiqiaoZhou/BALM-TSF,
How to Make Museums More Interactive? Case Study of Artistic Chatbot,"Filip J. Kucia, Bartosz Grabek, Szymon D. Trochimiak, Anna Wróblewska",2025-08-30,2509.00572v1,http://arxiv.org/abs/2509.00572v1,http://arxiv.org/pdf/2509.00572v1,information_retrieval,cs.HC,"Conversational agents powered by Large Language Models (LLMs) are
increasingly utilized in educational settings, in particular in individual
closed digital environments, yet their potential adoption in the physical
learning environments like cultural heritage sites, museums, and art galleries
remains relatively unexplored. In this study, we present Artistic Chatbot, a
voice-to-voice RAG-powered chat system to support informal learning and enhance
visitor engagement during a live art exhibition celebrating the 15th
anniversary of the Faculty of Media Art at the Warsaw Academy of Fine Arts,
Poland. The question answering (QA) chatbot responded to free-form spoken
questions in Polish using the context retrieved from a curated, domain-specific
knowledge base consisting of 226 documents provided by the organizers,
including faculty information, art magazines, books, and journals. We describe
the key aspects of the system architecture and user interaction design, as well
as discuss the practical challenges associated with deploying chatbots at
public cultural sites. Our findings, based on interaction analysis, demonstrate
that chatbots such as Artistic Chatbot effectively maintain responses grounded
in exhibition content (60\% of responses directly relevant), even when faced
with unpredictable queries outside the target domain, showing their potential
for increasing interactivity in public cultural sites.
  GitHub project page: https://github.com/cinekucia/artistic-chatbot-cikm2025",https://github.com/cinekucia/artistic-chatbot-cikm2025,"7 pages, 3 figures"
CRouting: Reducing Expensive Distance Calls in Graph-Based Approximate Nearest Neighbor Search,"Zhenxin Li, Shuibing He, Jiahao Guo, Xuechen Zhang, Xian-He Sun, Gang Chen",2025-08-30,2509.00365v1,http://arxiv.org/abs/2509.00365v1,http://arxiv.org/pdf/2509.00365v1,information_retrieval,cs.DB,"Approximate nearest neighbor search (ANNS) is a crucial problem in
information retrieval and AI applications. Recently, there has been a surge of
interest in graph-based ANNS algorithms due to their superior efficiency and
accuracy. However, the repeated computation of distances in high-dimensional
spaces constitutes the primary time cost of graph-based methods. To accelerate
the search, we propose a novel routing strategy named CRouting, which bypasses
unnecessary distance computations by exploiting the angle distributions of
high-dimensional vectors. CRouting is designed as a plugin to optimize existing
graph-based search with minimal code modifications. Our experiments show that
CRouting reduces the number of distance computations by up to 41.5% and boosts
queries per second by up to 1.48$\times$ on two predominant graph indexes, HNSW
and NSG. Code is publicly available at https://github.com/ISCS-ZJU/CRouting.",https://github.com/ISCS-ZJU/CRouting,
NewsReX: A More Efficient Approach to News Recommendation with Keras 3 and JAX,"Igor L. R. Azevedo, Toyotaro Suzumura, Yuichiro Yasui",2025-08-29,2508.21572v1,http://arxiv.org/abs/2508.21572v1,http://arxiv.org/pdf/2508.21572v1,information_retrieval,cs.IR,"Reproducing and comparing results in news recommendation research has become
increasingly difficult. This is due to a fragmented ecosystem of diverse
codebases, varied configurations, and mainly due to resource-intensive models.
We introduce NewsReX, an open-source library designed to streamline this
process. Our key contribution is a modern implementation built on Keras 3 and
JAX, which provides an increase in computational efficiency. Experiments show
that NewsReX is faster than current implementations. To support broader
research, we provide a straightforward guide and scripts for training models on
custom datasets. We validated this functionality using a proprietary Japanese
news dataset from Nikkei News, a leading Japanese media corporation renowned
for its comprehensive coverage of business, economic, and financial news.
NewsReX makes reproducing complex experiments faster and more accessible to a
wider range of hardware making sure the speed up it also achieved for less
powerful GPUs, like an 8GB RTX 3060 Ti. Beyond the library, this paper offers
an analysis of key training parameters often overlooked in the literature,
including the effect of different negative sampling strategies, the varying
number of epochs, the impact of random batching, and more. This supplementary
analysis serves as a valuable reference for future research, aiming to reduce
redundant computation when comparing baselines and guide best practices. Code
available at https://github.com/igor17400/NewsReX.",https://github.com/igor17400/NewsReX,
Diffusion-based Multi-modal Synergy Interest Network for Click-through Rate Prediction,"Xiaoxi Cui, Weihai Lu, Yu Tong, Yiheng Li, Zhejun Zhao",2025-08-29,2508.21460v1,http://arxiv.org/abs/2508.21460v1,http://arxiv.org/pdf/2508.21460v1,information_retrieval,cs.IR,"In click-through rate prediction, click-through rate prediction is used to
model users' interests. However, most of the existing CTR prediction methods
are mainly based on the ID modality. As a result, they are unable to
comprehensively model users' multi-modal preferences. Therefore, it is
necessary to introduce multi-modal CTR prediction. Although it seems appealing
to directly apply the existing multi-modal fusion methods to click-through rate
prediction models, these methods (1) fail to effectively disentangle
commonalities and specificities across different modalities; (2) fail to
consider the synergistic effects between modalities and model the complex
interactions between modalities.
  To address the above issues, this paper proposes the Diffusion-based
Multi-modal Synergy Interest Network (Diff-MSIN) framework for click-through
prediction. This framework introduces three innovative modules: the Multi-modal
Feature Enhancement (MFE) Module Synergistic Relationship Capture (SRC) Module,
and the Feature Dynamic Adaptive Fusion (FDAF) Module. The MFE Module and SRC
Module extract synergistic, common, and special information among different
modalities. They effectively enhances the representation of the modalities,
improving the overall quality of the fusion. To encourage distinctiveness among
different features, we design a Knowledge Decoupling method. Additionally, the
FDAF Module focuses on capturing user preferences and reducing fusion noise. To
validate the effectiveness of the Diff-MSIN framework, we conducted extensive
experiments using the Rec-Tmall and three Amazon datasets. The results
demonstrate that our approach yields a significant improvement of at least
1.67% compared to the baseline, highlighting its potential for enhancing
multi-modal recommendation systems. Our code is available at the following
link: https://github.com/Cxx-0/Diff-MSIN.",https://github.com/Cxx-0/Diff-MSIN,SIGIR 2025
Stairway to Fairness: Connecting Group and Individual Fairness,"Theresia Veronika Rampisela, Maria Maistro, Tuukka Ruotsalo, Falk Scholer, Christina Lioma",2025-08-29,2508.21334v1,http://arxiv.org/abs/2508.21334v1,http://arxiv.org/pdf/2508.21334v1,information_retrieval,cs.IR,"Fairness in recommender systems (RSs) is commonly categorised into group
fairness and individual fairness. However, there is no established scientific
understanding of the relationship between the two fairness types, as prior work
on both types has used different evaluation measures or evaluation objectives
for each fairness type, thereby not allowing for a proper comparison of the
two. As a result, it is currently not known how increasing one type of fairness
may affect the other. To fill this gap, we study the relationship of group and
individual fairness through a comprehensive comparison of evaluation measures
that can be used for both fairness types. Our experiments with 8 runs across 3
datasets show that recommendations that are highly fair for groups can be very
unfair for individuals. Our finding is novel and useful for RS practitioners
aiming to improve the fairness of their systems. Our code is available at:
https://github.com/theresiavr/stairway-to-fairness.",https://github.com/theresiavr/stairway-to-fairness,Accepted to RecSys 2025 (short paper)
SEAL: Structure and Element Aware Learning to Improve Long Structured Document Retrieval,"Xinhao Huang, Zhibo Ren, Yipeng Yu, Ying Zhou, Zulong Chen, Zeyi Wen",2025-08-28,2508.20778v2,http://arxiv.org/abs/2508.20778v2,http://arxiv.org/pdf/2508.20778v2,information_retrieval,cs.IR,"In long structured document retrieval, existing methods typically fine-tune
pre-trained language models (PLMs) using contrastive learning on datasets
lacking explicit structural information. This practice suffers from two
critical issues: 1) current methods fail to leverage structural features and
element-level semantics effectively, and 2) the lack of datasets containing
structural metadata. To bridge these gaps, we propose \our, a novel contrastive
learning framework. It leverages structure-aware learning to preserve semantic
hierarchies and masked element alignment for fine-grained semantic
discrimination. Furthermore, we release \dataset, a long structured document
retrieval dataset with rich structural annotations. Extensive experiments on
both released and industrial datasets across various modern PLMs, along with
online A/B testing, demonstrate consistent performance improvements, boosting
NDCG@10 from 73.96\% to 77.84\% on BGE-M3. The resources are available at
https://github.com/xinhaoH/SEAL.",https://github.com/xinhaoH/SEAL,Accepted at EMNLP 2025 Main Conference
Refining Text Generation for Realistic Conversational Recommendation via Direct Preference Optimization,"Manato Tajiri, Michimasa Inaba",2025-08-27,2508.19918v3,http://arxiv.org/abs/2508.19918v3,http://arxiv.org/pdf/2508.19918v3,information_retrieval,cs.IR,"Conversational Recommender Systems (CRSs) aim to elicit user preferences via
natural dialogue to provide suitable item recommendations. However, current
CRSs often deviate from realistic human interactions by rapidly recommending
items in brief sessions. This work addresses this gap by leveraging Large
Language Models (LLMs) to generate dialogue summaries from dialogue history and
item recommendation information from item description. This approach enables
the extraction of both explicit user statements and implicit preferences
inferred from the dialogue context. We introduce a method using Direct
Preference Optimization (DPO) to ensure dialogue summary and item
recommendation information are rich in information crucial for effective
recommendations. Experiments on two public datasets validate our method's
effectiveness in fostering more natural and realistic conversational
recommendation processes. Our implementation is publicly available at:
https://github.com/UEC-InabaLab/Refining-LLM-Text",https://github.com/UEC-InabaLab/Refining-LLM-Text,Accepted to EMNLP 2025 Main Conference
Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval,"Yixuan Tang, Yuanyuan Shi, Yiqun Sun, Anthony Kum Hoe Tung",2025-08-27,2508.19758v2,http://arxiv.org/abs/2508.19758v2,http://arxiv.org/pdf/2508.19758v2,information_retrieval,cs.CL,"Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.",https://github.com/tangyixuan/NEWSCOPE,Accepted by EMNLP 2025
Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset,"Sumon Kanti Dey, Jeanne M. Powell, Azra Ismail, Jeanmarie Perrone, Abeed Sarker",2025-08-26,2508.19467v1,http://arxiv.org/abs/2508.19467v1,http://arxiv.org/pdf/2508.19467v1,information_retrieval,cs.CL,"Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.",https://github.com/SumonKantiDey/Reddit_Impacts_NER,Dataset and code: https://github.com/SumonKantiDey/Reddit_Impacts_NER
CRouting: Reducing Expensive Distance Calls in Graph-Based Approximate Nearest Neighbor Search,"Zhenxin Li, Shuibing He, Jiahao Guo, Xuechen Zhang, Xian-He Sun, Gang Chen",2025-08-30,2509.00365v1,http://arxiv.org/abs/2509.00365v1,http://arxiv.org/pdf/2509.00365v1,databases,cs.DB,"Approximate nearest neighbor search (ANNS) is a crucial problem in
information retrieval and AI applications. Recently, there has been a surge of
interest in graph-based ANNS algorithms due to their superior efficiency and
accuracy. However, the repeated computation of distances in high-dimensional
spaces constitutes the primary time cost of graph-based methods. To accelerate
the search, we propose a novel routing strategy named CRouting, which bypasses
unnecessary distance computations by exploiting the angle distributions of
high-dimensional vectors. CRouting is designed as a plugin to optimize existing
graph-based search with minimal code modifications. Our experiments show that
CRouting reduces the number of distance computations by up to 41.5% and boosts
queries per second by up to 1.48$\times$ on two predominant graph indexes, HNSW
and NSG. Code is publicly available at https://github.com/ISCS-ZJU/CRouting.",https://github.com/ISCS-ZJU/CRouting,
ST-Raptor: LLM-Powered Semi-Structured Table Question Answering,"Zirui Tang, Boyu Niu, Xuanhe Zhou, Boxiu Li, Wei Zhou, Jiannan Wang, Guoliang Li, Xinyi Zhang, Fan Wu",2025-08-25,2508.18190v3,http://arxiv.org/abs/2508.18190v3,http://arxiv.org/pdf/2508.18190v3,databases,cs.AI,"Semi-structured tables, widely used in real-world applications (e.g.,
financial reports, medical records, transactional orders), often involve
flexible and complex layouts (e.g., hierarchical headers and merged cells).
These tables generally rely on human analysts to interpret table layouts and
answer relevant natural language questions, which is costly and inefficient. To
automate the procedure, existing methods face significant challenges. First,
methods like NL2SQL require converting semi-structured tables into structured
ones, which often causes substantial information loss. Second, methods like
NL2Code and multi-modal LLM QA struggle to understand the complex layouts of
semi-structured tables and cannot accurately answer corresponding questions. To
this end, we propose ST-Raptor, a tree-based framework for semi-structured
table question answering using large language models. First, we introduce the
Hierarchical Orthogonal Tree (HO-Tree), a structural model that captures
complex semi-structured table layouts, along with an effective algorithm for
constructing the tree. Second, we define a set of basic tree operations to
guide LLMs in executing common QA tasks. Given a user question, ST-Raptor
decomposes it into simpler sub-questions, generates corresponding tree
operation pipelines, and conducts operation-table alignment for accurate
pipeline execution. Third, we incorporate a two-stage verification mechanism:
forward validation checks the correctness of execution steps, while backward
validation evaluates answer reliability by reconstructing queries from
predicted answers. To benchmark the performance, we present SSTQA, a dataset of
764 questions over 102 real-world semi-structured tables. Experiments show that
ST-Raptor outperforms nine baselines by up to 20% in answer accuracy. The code
is available at https://github.com/weAIDB/ST-Raptor.",https://github.com/weAIDB/ST-Raptor,"Extension of our SIGMOD 2026 paper. Please refer to source code
  available at: https://github.com/weAIDB/ST-Raptor"
PGTuner: An Efficient Framework for Automatic and Transferable Configuration Tuning of Proximity Graphs,"Hao Duan, Yitong Song, Bin Yao, Anqi Liang",2025-08-25,2508.17886v1,http://arxiv.org/abs/2508.17886v1,http://arxiv.org/pdf/2508.17886v1,databases,cs.DB,"Approximate Nearest Neighbor Search (ANNS) plays a crucial role in many key
areas. Proximity graphs (PGs) are the leading method for ANNS, offering the
best balance between query efficiency and accuracy. However, their performance
heavily depends on various construction and query parameters, which are
difficult to optimize due to their complex inter-dependencies. Given that users
often prioritize specific accuracy levels, efficiently identifying the optimal
PG configurations to meet these targets is essential. Although some studies
have explored automatic configuration tuning for PGs, they are limited by
inefficiencies and suboptimal results. These issues stem from the need to
construct numerous PGs for searching and re-tuning from scratch whenever the
dataset changes, as well as the failure to capture the complex dependencies
between configurations, query performance, and tuning objectives.
  To address these challenges, we propose PGTuner, an efficient framework for
automatic PG configuration tuning leveraging pre-training knowledge and model
transfer techniques. PGTuner improves efficiency through a pre-trained query
performance prediction (QPP) model, eliminating the need to build multiple PGs.
It also features a deep reinforcement learning-based parameter configuration
recommendation (PCR) model to recommend optimal configurations for specific
datasets and accuracy targets. Additionally, PGTuner incorporates
out-of-distribution detection and deep active learning for efficient tuning in
dynamic scenarios and transferring to new datasets. Extensive experiments
demonstrate that PGTuner can stably achieve the top-level tuning effect across
different datasets while significantly improving tuning efficiency by up to
14.69X, with a 14.64X boost in dynamic scenarios. The code and data for PGTuner
are available online at https://github.com/hao-duan/PGTuner.",https://github.com/hao-duan/PGTuner,
Attribute Filtering in Approximate Nearest Neighbor Search: An In-depth Experimental Study,"Mocheng Li, Xiao Yan, Baotong Lu, Yue Zhang, James Cheng, Chenhao Ma",2025-08-22,2508.16263v1,http://arxiv.org/abs/2508.16263v1,http://arxiv.org/pdf/2508.16263v1,databases,cs.DB,"With the growing integration of structured and unstructured data, new methods
have emerged for performing similarity searches on vectors while honoring
structured attribute constraints, i.e., a process known as Filtering
Approximate Nearest Neighbor (Filtering ANN) search. Since many of these
algorithms have only appeared in recent years and are designed to work with a
variety of base indexing methods and filtering strategies, there is a pressing
need for a unified analysis that identifies their core techniques and enables
meaningful comparisons.
  In this work, we present a unified Filtering ANN search interface that
encompasses the latest algorithms and evaluate them extensively from multiple
perspectives. First, we propose a comprehensive taxonomy of existing Filtering
ANN algorithms based on attribute types and filtering strategies. Next, we
analyze their key components, i.e., index structures, pruning strategies, and
entry point selection, to elucidate design differences and tradeoffs. We then
conduct a broad experimental evaluation on 10 algorithms and 12 methods across
4 datasets (each with up to 10 million items), incorporating both synthetic and
real attributes and covering selectivity levels from 0.1% to 100%. Finally, an
in-depth component analysis reveals the influence of pruning, entry point
selection, and edge filtering costs on overall performance. Based on our
findings, we summarize the strengths and limitations of each approach, provide
practical guidelines for selecting appropriate methods, and suggest promising
directions for future research. Our code is available at:
https://github.com/lmccccc/FANNBench.",https://github.com/lmccccc/FANNBench,"15 pages, 15 figures, Accepted at SIGMOD 2026"
AmbiSQL: Interactive Ambiguity Detection and Resolution for Text-to-SQL,"Zhongjun Ding, Yin Lin, Tianjing Zeng",2025-08-21,2508.15276v1,http://arxiv.org/abs/2508.15276v1,http://arxiv.org/pdf/2508.15276v1,databases,cs.DB,"Text-to-SQL systems translate natural language questions into SQL queries,
providing substantial value for non-expert users. While large language models
(LLMs) show promising results for this task, they remain error-prone. Query
ambiguity has been recognized as a major obstacle for LLM-based Text-to-SQL
systems, leading to misinterpretation of user intent and inaccurate SQL
generation. We demonstrate AmbiSQL, an interactive system that automatically
detects query ambiguities and guides users through intuitive multiple-choice
questions to clarify their intent. Our approach introduces a fine-grained
ambiguity taxonomy for identifying ambiguities that affect database element
mapping and LLM reasoning, then incorporates user feedback to rewrite ambiguous
questions. Evaluation on an ambiguous query dataset shows that AmbiSQL achieves
87.2% precision in ambiguity detection and improves SQL exact match accuracy by
50% when integrated with Text-to-SQL systems. Our demonstration showcases the
significant performance gains and highlights the system's practical usability.
Code repo and demonstration are available at:
https://github.com/JustinzjDing/AmbiSQL.",https://github.com/JustinzjDing/AmbiSQL,
Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX,"Aayush Gupta, Arpit Bhayani",2025-08-17,2508.12485v1,http://arxiv.org/abs/2508.12485v1,http://arxiv.org/pdf/2508.12485v1,databases,cs.LG,"Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.",https://github.com/ayushgupta4897/DRL-Cache,"8 pages, 4 figures (system architecture, eviction path, training
  pipeline, and DQN algorithm), 2 tables. Code available at
  https://github.com/ayushgupta4897/DRL-Cache"
Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration,"Songyuan Sui, Hongyi Liu, Serena Liu, Li Li, Soo-Hyun Choi, Rui Chen, Xia Hu",2025-08-14,2508.15809v1,http://arxiv.org/abs/2508.15809v1,http://arxiv.org/pdf/2508.15809v1,databases,cs.CL,"Table understanding requires structured, multi-step reasoning. Large Language
Models (LLMs) struggle with it due to the structural complexity of tabular
data. Recently, multi-agent frameworks for SQL generation have shown promise in
tackling the challenges of understanding tabular data, but existing approaches
often suffer from limitations such as the inability to comprehend table
structure for reliable SQL generation, error propagation that results in
invalid queries, and over-reliance on execution correctness. To address these
issues, we propose Chain-of-Query (CoQ), a novel multi-agent framework for
SQL-aided table understanding. CoQ adopts natural-language-style
representations of table schemas to abstract away structural noise and enhance
understanding. It employs a clause-by-clause SQL generation strategy to improve
query quality and introduces a hybrid reasoning division that separates
SQL-based mechanical reasoning from LLM-based logical inference, thereby
reducing reliance on execution outcomes. Experiments with four models (both
closed- and open-source) across five widely used benchmarks show that
Chain-of-Query significantly improves accuracy from 61.11% to 74.77% and
reduces the invalid SQL rate from 9.48% to 3.34%, demonstrating its superior
effectiveness in table understanding. The code is available at
https://github.com/SongyuanSui/ChainofQuery.",https://github.com/SongyuanSui/ChainofQuery,"9 pages main content, 24 pages total including appendix, 6 figures"
