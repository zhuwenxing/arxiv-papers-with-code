title,authors,published,arxiv_id,url,pdf_url,category,primary_category,abstract,code_links,comment
MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning,"Hongjin Qian, Zheng Liu",2025-08-01,2508.00271v1,http://arxiv.org/abs/2508.00271v1,http://arxiv.org/pdf/2508.00271v1,information_retrieval,cs.AI,"In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.",https://github.com/qhjqhj00/MetaAgent,"Technical Report, 14 pages"
Melody-Lyrics Matching with Contrastive Alignment Loss,"Changhong Wang, Michel Olvera, Gaël Richard",2025-07-31,2508.00123v1,http://arxiv.org/abs/2508.00123v1,http://arxiv.org/pdf/2508.00123v1,information_retrieval,eess.AS,"The connection between music and lyrics is far beyond semantic bonds.
Conceptual pairs in the two modalities such as rhythm and rhyme, note duration
and syllabic stress, and structure correspondence, raise a compelling yet
seldom-explored direction in the field of music information retrieval. In this
paper, we present melody-lyrics matching (MLM), a new task which retrieves
potential lyrics for a given symbolic melody from text sources. Rather than
generating lyrics from scratch, MLM essentially exploits the relationships
between melody and lyrics. We propose a self-supervised representation learning
framework with contrastive alignment loss for melody and lyrics. This has the
potential to leverage the abundance of existing songs with paired melody and
lyrics. No alignment annotations are required. Additionally, we introduce
sylphone, a novel representation for lyrics at syllable-level activated by
phoneme identity and vowel stress. We demonstrate that our method can match
melody with coherent and singable lyrics with empirical results and intuitive
examples. We open source code and provide matching examples on the companion
webpage: https://github.com/changhongw/mlm.",https://github.com/changhongw/mlm,"10 pages, 7 figures, 3 tables. This work has been submitted to the
  IEEE for possible publication"
Personalized Education with Ranking Alignment Recommendation,"Haipeng Liu, Yuxuan Liu, Ting Long",2025-07-31,2507.23664v1,http://arxiv.org/abs/2507.23664v1,http://arxiv.org/pdf/2507.23664v1,information_retrieval,cs.AI,"Personalized question recommendation aims to guide individual students
through questions to enhance their mastery of learning targets. Most previous
methods model this task as a Markov Decision Process and use reinforcement
learning to solve, but they struggle with efficient exploration, failing to
identify the best questions for each student during training. To address this,
we propose Ranking Alignment Recommendation (RAR), which incorporates
collaborative ideas into the exploration mechanism, enabling more efficient
exploration within limited training episodes. Experiments show that RAR
effectively improves recommendation performance, and our framework can be
applied to any RL-based question recommender. Our code is available in
https://github.com/wuming29/RAR.git.",https://github.com/wuming29/RAR,
"Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation","Wei-Wei Du, Takuma Udagawa, Kei Tateno",2025-07-31,2507.23209v1,http://arxiv.org/abs/2507.23209v1,http://arxiv.org/pdf/2507.23209v1,information_retrieval,cs.IR,"Time intervals between purchasing items are a crucial factor in sequential
recommendation tasks, whereas existing approaches focus on item sequences and
often overlook by assuming the intervals between items are static. However,
dynamic intervals serve as a dimension that describes user profiling on not
only the history within a user but also different users with the same item
history. In this work, we propose IntervalLLM, a novel framework that
integrates interval information into LLM and incorporates the novel
interval-infused attention to jointly consider information of items and
intervals. Furthermore, unlike prior studies that address the cold-start
scenario only from the perspectives of users and items, we introduce a new
viewpoint: the interval perspective to serve as an additional metric for
evaluating recommendation methods on the warm and cold scenarios. Extensive
experiments on 3 benchmarks with both traditional- and LLM-based baselines
demonstrate that our IntervalLLM achieves not only 4.4% improvements in average
but also the best-performing warm and cold scenarios across all users, items,
and the proposed interval perspectives. In addition, we observe that the cold
scenario from the interval perspective experiences the most significant
performance drop among all recommendation methods. This finding underscores the
necessity of further research on interval-based cold challenges and our
integration of interval information in the realm of sequential recommendation
tasks. Our code is available here:
https://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM.",https://github.com/sony/ds-research-code,Accepted by RecSys 2025 short paper track
Generative Recommendation with Semantic IDs: A Practitioner's Handbook,"Clark Mingxuan Ju, Liam Collins, Leonardo Neves, Bhuvesh Kumar, Louis Yufeng Wang, Tong Zhao, Neil Shah",2025-07-29,2507.22224v1,http://arxiv.org/abs/2507.22224v1,http://arxiv.org/pdf/2507.22224v1,information_retrieval,cs.IR,"Generative recommendation (GR) has gained increasing attention for its
promising performance compared to traditional models. A key factor contributing
to the success of GR is the semantic ID (SID), which converts continuous
semantic representations (e.g., from large language models) into discrete ID
sequences. This enables GR models with SIDs to both incorporate semantic
information and learn collaborative filtering signals, while retaining the
benefits of discrete decoding. However, varied modeling techniques,
hyper-parameters, and experimental setups in existing literature make direct
comparisons between GR proposals challenging. Furthermore, the absence of an
open-source, unified framework hinders systematic benchmarking and extension,
slowing model iteration. To address this challenge, our work introduces and
open-sources a framework for Generative Recommendation with semantic ID, namely
GRID, specifically designed for modularity to facilitate easy component
swapping and accelerate idea iteration. Using GRID, we systematically
experiment with and ablate different components of GR models with SIDs on
public benchmarks. Our comprehensive experiments with GRID reveal that many
overlooked architectural components in GR models with SIDs substantially impact
performance. This offers both novel insights and validates the utility of an
open-source platform for robust benchmarking and GR research advancement. GRID
is open-sourced at https://github.com/snap-research/GRID.",https://github.com/snap-research/GRID,
StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation,"Satyananda Kashyap, Sola Shirai, Nandana Mihindukulasooriya, Horst Samulowitz",2025-07-28,2507.21340v1,http://arxiv.org/abs/2507.21340v1,http://arxiv.org/pdf/2507.21340v1,information_retrieval,cs.CL,"Extracting structured information from text, such as key-value pairs that
could augment tabular data, is quite useful in many enterprise use cases.
Although large language models (LLMs) have enabled numerous automated pipelines
for converting natural language into structured formats, there is still a lack
of benchmarks for evaluating their extraction quality, especially in specific
domains or focused documents specific to a given organization. Building such
benchmarks by manual annotations is labour-intensive and limits the size and
scalability of the benchmarks. In this work, we present StructText, an
end-to-end framework for automatically generating high-fidelity benchmarks for
key-value extraction from text using existing tabular data. It uses available
tabular data as structured ground truth, and follows a two-stage
``plan-then-execute'' pipeline to synthetically generate corresponding
natural-language text. To ensure alignment between text and structured source,
we introduce a multi-dimensional evaluation strategy that combines (a)
LLM-based judgments on factuality, hallucination, and coherence and (b)
objective extraction metrics measuring numeric and temporal accuracy. We
evaluated the proposed method on 71,539 examples across 49 datasets. Results
reveal that while LLMs achieve strong factual accuracy and avoid hallucination,
they struggle with narrative coherence in producing extractable text. Notably,
models presume numerical and temporal information with high fidelity yet this
information becomes embedded in narratives that resist automated extraction. We
release a framework, including datasets, evaluation tools, and baseline
extraction systems, to support continued research.",https://github.com/ibm/struct-text,"Data available:
  https://huggingface.co/datasets/ibm-research/struct-text and code available
  at: https://github.com/ibm/struct-text"
ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning,"Duc-Tai Dinh, Duc Anh Khoa Dinh",2025-07-28,2507.20564v1,http://arxiv.org/abs/2507.20564v1,http://arxiv.org/pdf/2507.20564v1,information_retrieval,cs.CL,"We present ZSE-Cap (Zero-Shot Ensemble for Captioning), our 4th place system
in Event-Enriched Image Analysis (EVENTA) shared task on article-grounded image
retrieval and captioning. Our zero-shot approach requires no finetuning on the
competition's data. For retrieval, we ensemble similarity scores from CLIP,
SigLIP, and DINOv2. For captioning, we leverage a carefully engineered prompt
to guide the Gemma 3 model, enabling it to link high-level events from the
article to the visual content in the image. Our system achieved a final score
of 0.42002, securing a top-4 position on the private test set, demonstrating
the effectiveness of combining foundation models through ensembling and
prompting. Our code is available at https://github.com/ductai05/ZSE-Cap.",https://github.com/ductai05/ZSE-Cap,
Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG,"Baiyu Chen, Wilson Wongso, Xiaoqian Hu, Yue Tan, Flora Salim",2025-07-27,2507.20136v1,http://arxiv.org/abs/2507.20136v1,http://arxiv.org/pdf/2507.20136v1,information_retrieval,cs.CL,"This paper presents the technical solution developed by team CRUISE for the
KDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn
(CRAG-MM) challenge. The challenge aims to address a critical limitation of
modern Vision Language Models (VLMs): their propensity to hallucinate,
especially when faced with egocentric imagery, long-tail entities, and complex,
multi-hop questions. This issue is particularly problematic in real-world
applications where users pose fact-seeking queries that demand high factual
accuracy across diverse modalities. To tackle this, we propose a robust,
multi-stage framework that prioritizes factual accuracy and truthfulness over
completeness. Our solution integrates a lightweight query router for
efficiency, a query-aware retrieval and summarization pipeline, a dual-pathways
generation and a post-hoc verification. This conservative strategy is designed
to minimize hallucinations, which incur a severe penalty in the competition's
scoring metric. Our approach achieved 3rd place in Task 1, demonstrating the
effectiveness of prioritizing answer reliability in complex multi-modal RAG
systems. Our implementation is available at
https://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .",https://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM,KDD Cup 2025 Meta CRAG-MM Challenge
Injecting External Knowledge into the Reasoning Process Enhances Retrieval-Augmented Generation,"Minghao Tang, Shiyu Ni, Jiafeng Guo, Keping Bi",2025-07-25,2507.19333v1,http://arxiv.org/abs/2507.19333v1,http://arxiv.org/pdf/2507.19333v1,information_retrieval,cs.IR,"Retrieval-augmented generation (RAG) has been widely adopted to augment large
language models (LLMs) with external knowledge for knowledge-intensive tasks.
However, its effectiveness is often undermined by the presence of noisy (i.e.,
low-quality) retrieved passages. Enhancing LLMs' robustness to such noise is
critical for improving the reliability of RAG systems. Recent advances have
equipped LLMs with strong reasoning and self-reflection capabilities, allowing
them to identify and correct errors in their reasoning process. Inspired by
this ability, we propose Passage Injection-a simple yet effective method that
explicitly incorporates retrieved passages into LLMs' reasoning process, aiming
to enhance the model's ability to recognize and resist noisy passages. We
validate Passage Injection under general RAG settings using BM25 as the
retriever. Experiments on four reasoning-enhanced LLMs across four factual QA
datasets demonstrate that Passage Injection significantly improves overall RAG
performance. Further analysis on two noisy retrieval settings-random noise,
where the model is provided irrelevant passages, and counterfactual noise,
where it is given misleading passages-shows that Passage Injection consistently
improves robustness. Controlled experiments confirm that Passage Injection can
also effectively leverage helpful passages. These findings suggest that
incorporating passages in LLMs' reasoning process is a promising direction for
building more robust RAG systems. The code can be found
\href{here}{https://github.com/mh-tang/Passage-Injection}.",https://github.com/mh-tang/Passage-Injection,
Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work,"Peter Eckmann, Adrian Barnett, Alexandra Bannach-Brown, Elisa Pilar Bascunan Atria, Guillaume Cabanac, Louise Delwen Owen Franzen, Małgorzata Anna Gazda, Kaitlyn Hair, James Howison, Halil Kilicoglu, Cyril Labbe, Sarah McCann, Vladislav Nachev, Martijn Roelandse, Maia Salholz-Hillel, Robert Schulz, Gerben ter Riet, Colby Vorland, Anita Bandrowski, Tracey Weissgerber",2025-07-23,2507.17991v1,http://arxiv.org/abs/2507.17991v1,http://arxiv.org/pdf/2507.17991v1,information_retrieval,cs.SE,"The causes of the reproducibility crisis include lack of standardization and
transparency in scientific reporting. Checklists such as ARRIVE and CONSORT
seek to improve transparency, but they are not always followed by authors and
peer review often fails to identify missing items. To address these issues,
there are several automated tools that have been designed to check different
rigor criteria. We have conducted a broad comparison of 11 automated tools
across 9 different rigor criteria from the ScreenIT group. We found some
criteria, including detecting open data, where the combination of tools showed
a clear winner, a tool which performed much better than other tools. In other
cases, including detection of inclusion and exclusion criteria, the combination
of tools exceeded the performance of any one tool. We also identified key areas
where tool developers should focus their effort to make their tool maximally
useful. We conclude with a set of insights and recommendations for stakeholders
in the development of rigor and transparency detection tools. The code and data
for the study is available at https://github.com/PeterEckmann1/tool-comparison.",https://github.com/PeterEckmann1/tool-comparison,
Leave No One Behind: Fairness-Aware Cross-Domain Recommender Systems for Non-Overlapping Users,"Weixin Chen, Yuhan Zhao, Li Chen, Weike Pan",2025-07-23,2507.17749v1,http://arxiv.org/abs/2507.17749v1,http://arxiv.org/pdf/2507.17749v1,information_retrieval,cs.IR,"Cross-domain recommendation (CDR) methods predominantly leverage overlapping
users to transfer knowledge from a source domain to a target domain. However,
through empirical studies, we uncover a critical bias inherent in these
approaches: while overlapping users experience significant enhancements in
recommendation quality, non-overlapping users benefit minimally and even face
performance degradation. This unfairness may erode user trust, and,
consequently, negatively impact business engagement and revenue. To address
this issue, we propose a novel solution that generates virtual source-domain
users for non-overlapping target-domain users. Our method utilizes a dual
attention mechanism to discern similarities between overlapping and
non-overlapping users, thereby synthesizing realistic virtual user embeddings.
We further introduce a limiter component that ensures the generated virtual
users align with real-data distributions while preserving each user's unique
characteristics. Notably, our method is model-agnostic and can be seamlessly
integrated into any CDR model. Comprehensive experiments conducted on three
public datasets with five CDR baselines demonstrate that our method effectively
mitigates the CDR non-overlapping user bias, without loss of overall accuracy.
Our code is publicly available at https://github.com/WeixinChen98/VUG.",https://github.com/WeixinChen98/VUG,Accepted by RecSys 2025
BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision Assessment on Semi-Structured Profiles,"Junhua Liu, Roy Ka-Wei Lee, Kwan Hui Lim",2025-07-23,2507.17472v1,http://arxiv.org/abs/2507.17472v1,http://arxiv.org/pdf/2507.17472v1,information_retrieval,cs.LG,"Human decision-making in high-stakes domains often relies on expertise and
heuristics, but is vulnerable to hard-to-detect cognitive biases that threaten
fairness and long-term outcomes. This work presents a novel approach to
enhancing complex decision-making workflows through the integration of
hierarchical learning alongside various enhancements. Focusing on university
admissions as a representative high-stakes domain, we propose BGM-HAN, an
enhanced Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network,
designed to effectively model semi-structured applicant data. BGM-HAN captures
multi-level representations that are crucial for nuanced assessment, improving
both interpretability and predictive performance. Experimental results on real
admissions data demonstrate that our proposed model significantly outperforms
both state-of-the-art baselines from traditional machine learning to large
language models, offering a promising framework for augmenting decision-making
in domains where structure, context, and fairness matter. Source code is
available at: https://github.com/junhua/bgm-han.",https://github.com/junhua/bgm-han,Accepted at ASONAM 2025
HLFormer: Enhancing Partially Relevant Video Retrieval with Hyperbolic Learning,"Jun Li, Jinpeng Wang, Chaolei Tan, Niu Lian, Long Chen, Yaowei Wang, Min Zhang, Shu-Tao Xia, Bin Chen",2025-07-23,2507.17402v2,http://arxiv.org/abs/2507.17402v2,http://arxiv.org/pdf/2507.17402v2,information_retrieval,cs.CV,"Partially Relevant Video Retrieval (PRVR) addresses the critical challenge of
matching untrimmed videos with text queries describing only partial content.
Existing methods suffer from geometric distortion in Euclidean space that
sometimes misrepresents the intrinsic hierarchical structure of videos and
overlooks certain hierarchical semantics, ultimately leading to suboptimal
temporal modeling. To address this issue, we propose the first hyperbolic
modeling framework for PRVR, namely HLFormer, which leverages hyperbolic space
learning to compensate for the suboptimal hierarchical modeling capabilities of
Euclidean space. Specifically, HLFormer integrates the Lorentz Attention Block
and Euclidean Attention Block to encode video embeddings in hybrid spaces,
using the Mean-Guided Adaptive Interaction Module to dynamically fuse features.
Additionally, we introduce a Partial Order Preservation Loss to enforce ""text <
video"" hierarchy through Lorentzian cone constraints. This approach further
enhances cross-modal matching by reinforcing partial relevance between video
content and text queries. Extensive experiments show that HLFormer outperforms
state-of-the-art methods. Code is released at
https://github.com/lijun2005/ICCV25-HLFormer.",https://github.com/lijun2005/ICCV25-HLFormer,"Accepted by ICCV'25. 13 pages, 6 figures, 4 tables"
EndoFinder: Online Lesion Retrieval for Explainable Colorectal Polyp Diagnosis Leveraging Latent Scene Representations,"Ruijie Yang, Yan Zhu, Peiyao Fu, Yizhe Zhang, Zhihua Wang, Quanlin Li, Pinghong Zhou, Xian Yang, Shuo Wang",2025-07-23,2507.17323v1,http://arxiv.org/abs/2507.17323v1,http://arxiv.org/pdf/2507.17323v1,information_retrieval,cs.IR,"Colorectal cancer (CRC) remains a leading cause of cancer-related mortality,
underscoring the importance of timely polyp detection and diagnosis. While deep
learning models have improved optical-assisted diagnostics, they often demand
extensive labeled datasets and yield ""black-box"" outputs with limited
interpretability. In this paper, we propose EndoFinder, an online polyp
retrieval framework that leverages multi-view scene representations for
explainable and scalable CRC diagnosis. First, we develop a Polyp-aware Image
Encoder by combining contrastive learning and a reconstruction task, guided by
polyp segmentation masks. This self-supervised approach captures robust
features without relying on large-scale annotated data. Next, we treat each
polyp as a three-dimensional ""scene"" and introduce a Scene Representation
Transformer, which fuses multiple views of the polyp into a single latent
representation. By discretizing this representation through a hashing layer,
EndoFinder enables real-time retrieval from a compiled database of historical
polyp cases, where diagnostic information serves as interpretable references
for new queries. We evaluate EndoFinder on both public and newly collected
polyp datasets for re-identification and pathology classification. Results show
that EndoFinder outperforms existing methods in accuracy while providing
transparent, retrieval-based insights for clinical decision-making. By
contributing a novel dataset and a scalable, explainable framework, our work
addresses key challenges in polyp diagnosis and offers a promising direction
for more efficient AI-driven colonoscopy workflows. The source code is
available at https://github.com/ku262/EndoFinder-Scene.",https://github.com/ku262/EndoFinder-Scene,
StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation,"Satyananda Kashyap, Sola Shirai, Nandana Mihindukulasooriya, Horst Samulowitz",2025-07-28,2507.21340v1,http://arxiv.org/abs/2507.21340v1,http://arxiv.org/pdf/2507.21340v1,databases,cs.CL,"Extracting structured information from text, such as key-value pairs that
could augment tabular data, is quite useful in many enterprise use cases.
Although large language models (LLMs) have enabled numerous automated pipelines
for converting natural language into structured formats, there is still a lack
of benchmarks for evaluating their extraction quality, especially in specific
domains or focused documents specific to a given organization. Building such
benchmarks by manual annotations is labour-intensive and limits the size and
scalability of the benchmarks. In this work, we present StructText, an
end-to-end framework for automatically generating high-fidelity benchmarks for
key-value extraction from text using existing tabular data. It uses available
tabular data as structured ground truth, and follows a two-stage
``plan-then-execute'' pipeline to synthetically generate corresponding
natural-language text. To ensure alignment between text and structured source,
we introduce a multi-dimensional evaluation strategy that combines (a)
LLM-based judgments on factuality, hallucination, and coherence and (b)
objective extraction metrics measuring numeric and temporal accuracy. We
evaluated the proposed method on 71,539 examples across 49 datasets. Results
reveal that while LLMs achieve strong factual accuracy and avoid hallucination,
they struggle with narrative coherence in producing extractable text. Notably,
models presume numerical and temporal information with high fidelity yet this
information becomes embedded in narratives that resist automated extraction. We
release a framework, including datasets, evaluation tools, and baseline
extraction systems, to support continued research.",https://github.com/ibm/struct-text,"Data available:
  https://huggingface.co/datasets/ibm-research/struct-text and code available
  at: https://github.com/ibm/struct-text"
MH-GIN: Multi-scale Heterogeneous Graph-based Imputation Network for AIS Data (Extended Version),"Hengyu Liu, Tianyi Li, Yuqiang He, Kristian Torp, Yushuai Li, Christian S. Jensen",2025-07-27,2507.20362v1,http://arxiv.org/abs/2507.20362v1,http://arxiv.org/pdf/2507.20362v1,databases,cs.LG,"Location-tracking data from the Automatic Identification System, much of
which is publicly available, plays a key role in a range of maritime safety and
monitoring applications. However, the data suffers from missing values that
hamper downstream applications. Imputing the missing values is challenging
because the values of different heterogeneous attributes are updated at diverse
rates, resulting in the occurrence of multi-scale dependencies among
attributes. Existing imputation methods that assume similar update rates across
attributes are unable to capture and exploit such dependencies, limiting their
imputation accuracy. We propose MH-GIN, a Multi-scale Heterogeneous Graph-based
Imputation Network that aims improve imputation accuracy by capturing
multi-scale dependencies. Specifically, MH-GIN first extracts multi-scale
temporal features for each attribute while preserving their intrinsic
heterogeneous characteristics. Then, it constructs a multi-scale heterogeneous
graph to explicitly model dependencies between heterogeneous attributes to
enable more accurate imputation of missing values through graph propagation.
Experimental results on two real-world datasets find that MH-GIN is capable of
an average 57% reduction in imputation errors compared to state-of-the-art
methods, while maintaining computational efficiency. The source code and
implementation details of MH-GIN are publicly available
https://github.com/hyLiu1994/MH-GIN.",https://github.com/hyLiu1994/MH-GIN,"18 pages, 4 figures"
Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion,"Zizhao Zhang, Tianxiang Zhao, Yu Sun, Liping Sun, Jichuan Kang",2025-07-18,2507.13721v1,http://arxiv.org/abs/2507.13721v1,http://arxiv.org/pdf/2507.13721v1,databases,cs.LG,"To address the challenges posed by cascading reactions caused by component
failures in autonomous cargo ships (ACS) and the uncertainties in emergency
decision-making, this paper proposes a novel hybrid feature fusion framework
for constructing a graph-structured dataset of failure modes. By employing an
improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency
is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to
the NSGA-II and CSA search algorithms, respectively. A hierarchical feature
fusion framework is constructed, using Word2Vec encoding to encode
subsystem/component features, BERT-KPCA to process failure modes/reasons, and
Sentence-BERT to quantify the semantic association between failure impact and
emergency decision-making. The dataset covers 12 systems, 1,262 failure modes,
and 6,150 propagation paths. Validation results show that the GATE-GNN model
achieves a classification accuracy of 0.735, comparable to existing benchmarks.
Additionally, a silhouette coefficient of 0.641 indicates that the features are
highly distinguishable. In the label prediction results, the Shore-based
Meteorological Service System achieved an F1 score of 0.93, demonstrating high
prediction accuracy. This paper not only provides a solid foundation for
failure analysis in autonomous cargo ships but also offers reliable support for
fault diagnosis, risk assessment, and intelligent decision-making systems. The
link to the dataset is
https://github.com/wojiufukele/Graph-Structured-about-CSA.",https://github.com/wojiufukele/Graph-Structured-about-CSA,
TOPJoin: A Context-Aware Multi-Criteria Approach for Joinable Column Search,"Harsha Kokel, Aamod Khatiwada, Tejaswini Pedapati, Haritha Ananthakrishnan, Oktie Hassanzadeh, Horst Samulowitz, Kavitha Srinivas",2025-07-15,2507.11505v1,http://arxiv.org/abs/2507.11505v1,http://arxiv.org/pdf/2507.11505v1,databases,cs.DB,"One of the major challenges in enterprise data analysis is the task of
finding joinable tables that are conceptually related and provide meaningful
insights. Traditionally, joinable tables have been discovered through a search
for similar columns, where two columns are considered similar syntactically if
there is a set overlap or they are considered similar semantically if either
the column embeddings or value embeddings are closer in the embedding space.
However, for enterprise data lakes, column similarity is not sufficient to
identify joinable columns and tables. The context of the query column is
important. Hence, in this work, we first define context-aware column
joinability. Then we propose a multi-criteria approach, called TOPJoin, for
joinable column search. We evaluate TOPJoin against existing join search
baselines over one academic and one real-world join search benchmark. Through
experiments, we find that TOPJoin performs better on both benchmarks than the
baselines.",https://github.com/IBM/ContextAwareJoin,"VLDB 2025 Workshop: Tabular Data Analysis (TaDA); The source code,
  data, and/or other artifacts have been made available at
  https://github.com/IBM/ContextAwareJoin"
