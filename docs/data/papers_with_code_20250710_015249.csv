title,authors,published,arxiv_id,url,pdf_url,category,primary_category,abstract,code_links,comment
Unconditional Diffusion for Generative Sequential Recommendation,"Yimeng Bai, Yang Zhang, Sihao Ding, Shaohui Ruan, Han Yao, Danhui Guan, Fuli Feng, Tat-Seng Chua",2025-07-08,2507.06121v1,http://arxiv.org/abs/2507.06121v1,http://arxiv.org/pdf/2507.06121v1,information_retrieval,cs.IR,"Diffusion models, known for their generative ability to simulate data
creation through noise-adding and denoising processes, have emerged as a
promising approach for building generative recommenders. To incorporate user
history for personalization, existing methods typically adopt a conditional
diffusion framework, where the reverse denoising process of reconstructing
items from noise is modified to be conditioned on the user history. However,
this design may fail to fully utilize historical information, as it gets
distracted by the need to model the ""item $\leftrightarrow$ noise"" translation.
This motivates us to reformulate the diffusion process for sequential
recommendation in an unconditional manner, treating user history (instead of
noise) as the endpoint of the forward diffusion process (i.e., the starting
point of the reverse process), rather than as a conditional input. This
formulation allows for exclusive focus on modeling the ""item $\leftrightarrow$
history"" translation. To this end, we introduce Brownian Bridge Diffusion
Recommendation (BBDRec). By leveraging a Brownian bridge process, BBDRec
enforces a structured noise addition and denoising mechanism, ensuring that the
trajectories are constrained towards a specific endpoint -- user history,
rather than noise. Extensive experiments demonstrate BBDRec's effectiveness in
enhancing sequential recommendation performance. The source code is available
at https://github.com/baiyimeng/BBDRec.",https://github.com/baiyimeng/BBDRec,
Tile-Based ViT Inference with Visual-Cluster Priors for Zero-Shot Multi-Species Plant Identification,"Murilo Gustineli, Anthony Miyaguchi, Adrian Cheung, Divyansh Khattak",2025-07-08,2507.06093v1,http://arxiv.org/abs/2507.06093v1,http://arxiv.org/pdf/2507.06093v1,information_retrieval,cs.CV,"We describe DS@GT's second-place solution to the PlantCLEF 2025 challenge on
multi-species plant identification in vegetation quadrat images. Our pipeline
combines (i) a fine-tuned Vision Transformer ViTD2PC24All for patch-level
inference, (ii) a 4x4 tiling strategy that aligns patch size with the network's
518x518 receptive field, and (iii) domain-prior adaptation through PaCMAP +
K-Means visual clustering and geolocation filtering. Tile predictions are
aggregated by majority vote and re-weighted with cluster-specific Bayesian
priors, yielding a macro-averaged F1 of 0.348 (private leaderboard) while
requiring no additional training. All code, configuration files, and
reproducibility scripts are publicly available at
https://github.com/dsgt-arc/plantclef-2025.",https://github.com/dsgt-arc/plantclef-2025,
When Transformers Meet Recommenders: Integrating Self-Attentive Sequential Recommendation with Fine-Tuned LLMs,Kechen Liu,2025-07-08,2507.05733v1,http://arxiv.org/abs/2507.05733v1,http://arxiv.org/pdf/2507.05733v1,information_retrieval,cs.IR,"Self-Attentive Sequential Recommendation (SASRec) effectively captures
long-term user preferences by applying attention mechanisms to historical
interactions. Concurrently, the rise of Large Language Models (LLMs) has
motivated research into LLM-based recommendation, which leverages their
powerful generalization and language understanding capabilities. However, LLMs
often lack the domain-specific knowledge and collaborative signals essential
for high-quality recommendations when relying solely on textual prompts. To
address this limitation, this study proposes SASRecLLM, a novel framework that
integrates SASRec as a collaborative encoder with an LLM fine-tuned using
Low-Rank Adaptation (LoRA). The components are connected via a mapping layer to
align their dimensional spaces, and three targeted training strategies are
designed to optimize the hybrid architecture. Extensive experiments on multiple
datasets demonstrate that SASRecLLM achieves robust and consistent improvements
over strong baselines in both cold-start and warm-start scenarios. This work
advances the field of LLM-based recommendation by presenting a modular and
effective paradigm for fusing structured collaborative filtering with the
semantic power of fine-tuned LLMs. The implementation is available on GitHub:
https://github.com/kechenkristin/RecLLM",https://github.com/kechenkristin/RecLLM,
From ID-based to ID-free: Rethinking ID Effectiveness in Multimodal Collaborative Filtering Recommendation,"Guohao Li, Li Jing, Jia Wu, Xuefei Li, Kai Zhu, Yue He",2025-07-08,2507.05715v1,http://arxiv.org/abs/2507.05715v1,http://arxiv.org/pdf/2507.05715v1,information_retrieval,cs.IR,"Most existing multimodal collaborative filtering recommendation (MCFRec)
methods rely heavily on ID features and multimodal content to enhance
recommendation performance. However, this paper reveals that ID features are
effective but have limited benefits in multimodal collaborative filtering
recommendation. Therefore, this paper systematically deconstruct the pros and
cons of ID features: (i) they provide initial embedding but lack semantic
richness, (ii) they provide a unique identifier for each user and item but
hinder generalization to untrained data, and (iii) they assist in aligning and
fusing multimodal features but may lead to representation shift. Based on these
insights, this paper proposes IDFREE, an ID-free multimodal collaborative
Filtering REcommEndation baseline. IDFREE replaces ID features with multimodal
features and positional encodings to generate semantically meaningful ID-free
embeddings. For ID-free multimodal collaborative filtering, it further proposes
an adaptive similarity graph module to construct dynamic user-user and
item-item graphs based on multimodal features. Then, an augmented user-item
graph encoder is proposed to construct more effective user and item encoding.
Finally, IDFREE achieves inter-multimodal alignment based on the contrastive
learning and uses Softmax loss as recommendation loss. Basic experiments on
three public datasets demonstrate that IDFREE outperforms existing ID-based
MCFRec methods, achieving an average performance gain of 72.24% across standard
metrics (Recall@5, 10, 20, 50 and NDCG@5, 10, 20, 50). Exploratory and extended
experiments further validate our findings on the limitations of ID features in
MCFRec. The code is released at https://github.com/G-H-Li/IDFREE.",https://github.com/G-H-Li/IDFREE,ACM MM'25 (Experimental supplementary version)
FindRec: Stein-Guided Entropic Flow for Multi-Modal Sequential Recommendation,"Maolin Wang, Yutian Xiao, Binhao Wang, Sheng Zhang, Shanshan Ye, Wanyu Wang, Hongzhi Yin, Ruocheng Guo, Zenglin Xu",2025-07-07,2507.04651v1,http://arxiv.org/abs/2507.04651v1,http://arxiv.org/pdf/2507.04651v1,information_retrieval,cs.IR,"Modern recommendation systems face significant challenges in processing
multimodal sequential data, particularly in temporal dynamics modeling and
information flow coordination. Traditional approaches struggle with
distribution discrepancies between heterogeneous features and noise
interference in multimodal signals. We propose \textbf{FindRec}~
(\textbf{F}lexible unified \textbf{in}formation \textbf{d}isentanglement for
multi-modal sequential \textbf{Rec}ommendation), introducing a novel
""information flow-control-output"" paradigm. The framework features two key
innovations: (1) A Stein kernel-based Integrated Information Coordination
Module (IICM) that theoretically guarantees distribution consistency between
multimodal features and ID streams, and (2) A cross-modal expert routing
mechanism that adaptively filters and combines multimodal features based on
their contextual relevance. Our approach leverages multi-head subspace
decomposition for routing stability and RBF-Stein gradient for unbiased
distribution alignment, enhanced by linear-complexity Mamba layers for
efficient temporal modeling. Extensive experiments on three real-world datasets
demonstrate FindRec's superior performance over state-of-the-art baselines,
particularly in handling long sequences and noisy multimodal inputs. Our
framework achieves both improved recommendation accuracy and enhanced model
interpretability through its modular design. The implementation code is
available anonymously online for easy
reproducibility~\footnote{https://github.com/Applied-Machine-Learning-Lab/FindRec}.",https://github.com/Applied-Machine-Learning-Lab/FindRec,Accepted by KDD 2025
Hierarchical Intent-guided Optimization with Pluggable LLM-Driven Semantics for Session-based Recommendation,"Jinpeng Chen, Jianxiang He, Huan Li, Senzhang Wang, Yuan Cao, Kaimin Wei, Zhenye Yang, Ye Ji",2025-07-07,2507.04623v1,http://arxiv.org/abs/2507.04623v1,http://arxiv.org/pdf/2507.04623v1,information_retrieval,cs.IR,"Session-based Recommendation (SBR) aims to predict the next item a user will
likely engage with, using their interaction sequence within an anonymous
session. Existing SBR models often focus only on single-session information,
ignoring inter-session relationships and valuable cross-session insights. Some
methods try to include inter-session data but struggle with noise and
irrelevant information, reducing performance. Additionally, most models rely on
item ID co-occurrence and overlook rich semantic details, limiting their
ability to capture fine-grained item features. To address these challenges, we
propose a novel hierarchical intent-guided optimization approach with pluggable
LLM-driven semantic learning for session-based recommendations, called HIPHOP.
First, we introduce a pluggable embedding module based on large language models
(LLMs) to generate high-quality semantic representations, enhancing item
embeddings. Second, HIPHOP utilizes graph neural networks (GNNs) to model item
transition relationships and incorporates a dynamic multi-intent capturing
module to address users' diverse interests within a session. Additionally, we
design a hierarchical inter-session similarity learning module, guided by user
intent, to capture global and local session relationships, effectively
exploring users' long-term and short-term interests. To mitigate noise, an
intent-guided denoising strategy is applied during inter-session learning.
Finally, we enhance the model's discriminative capability by using contrastive
learning to optimize session representations. Experiments on multiple datasets
show that HIPHOP significantly outperforms existing methods, demonstrating its
effectiveness in improving recommendation quality. Our code is available:
https://github.com/hjx159/HIPHOP.",https://github.com/hjx159/HIPHOP,
Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search,"Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yang Zhao, Hongjin Qian, Zhicheng Dou",2025-07-03,2507.02652v1,http://arxiv.org/abs/2507.02652v1,http://arxiv.org/pdf/2507.02652v1,information_retrieval,cs.AI,"Complex information needs in real-world search scenarios demand deep
reasoning and knowledge synthesis across diverse sources, which traditional
retrieval-augmented generation (RAG) pipelines struggle to address effectively.
Current reasoning-based approaches suffer from a fundamental limitation: they
use a single model to handle both high-level planning and detailed execution,
leading to inefficient reasoning and limited scalability. In this paper, we
introduce HiRA, a hierarchical framework that separates strategic planning from
specialized execution. Our approach decomposes complex search tasks into
focused subtasks, assigns each subtask to domain-specific agents equipped with
external tools and reasoning capabilities, and coordinates the results through
a structured integration mechanism. This separation prevents execution details
from disrupting high-level reasoning while enabling the system to leverage
specialized expertise for different types of information processing.
Experiments on four complex, cross-modal deep search benchmarks demonstrate
that HiRA significantly outperforms state-of-the-art RAG and agent-based
systems. Our results show improvements in both answer quality and system
efficiency, highlighting the effectiveness of decoupled planning and execution
for multi-step information seeking tasks. Our code is available at
https://github.com/ignorejjj/HiRA.",https://github.com/ignorejjj/HiRA,9 pages
Listwise Preference Alignment Optimization for Tail Item Recommendation,"Zihao Li, Chao Yang, Tong Zhang, Yakun Chen, Xianzhi Wang, Guandong Xu, Daoyi Dong",2025-07-03,2507.02255v1,http://arxiv.org/abs/2507.02255v1,http://arxiv.org/pdf/2507.02255v1,information_retrieval,cs.IR,"Preference alignment has achieved greater success on Large Language Models
(LLMs) and drawn broad interest in recommendation research. Existing preference
alignment methods for recommendation either require explicit reward modeling or
only support pairwise preference comparison. The former directly increases
substantial computational costs, while the latter hinders training efficiency
on negative samples. Moreover, no existing effort has explored preference
alignment solutions for tail-item recommendation. To bridge the above gaps, we
propose LPO4Rec, which extends the Bradley-Terry model from pairwise comparison
to listwise comparison, to improve the efficiency of model training.
Specifically, we derive a closed form optimal policy to enable more efficient
and effective training without explicit reward modeling. We also present an
adaptive negative sampling and reweighting strategy to prioritize tail items
during optimization and enhance performance in tail-item recommendations.
Besides, we theoretically prove that optimizing the listwise preference
optimization (LPO) loss is equivalent to maximizing the upper bound of the
optimal reward. Our experiments on three public datasets show that our method
outperforms 10 baselines by a large margin, achieving up to 50% performance
improvement while reducing 17.9% GPU memory usage when compared with direct
preference optimization (DPO) in tail-item recommendation. Our code is
available at https://github.com/Yuhanleeee/LPO4Rec.",https://github.com/Yuhanleeee/LPO4Rec,
Confidence and Stability of Global and Pairwise Scores in NLP Evaluation,"Georgii Levtsov, Dmitry Ustalov",2025-07-02,2507.01633v1,http://arxiv.org/abs/2507.01633v1,http://arxiv.org/pdf/2507.01633v1,information_retrieval,cs.CL,"With the advent of highly capable instruction-tuned neural language models,
benchmarking in natural language processing (NLP) is increasingly shifting
towards pairwise comparison leaderboards, such as LMSYS Arena, from traditional
global pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper
empirically investigates the strengths and weaknesses of both global scores and
pairwise comparisons to aid decision-making in selecting appropriate model
evaluation strategies. Through computational experiments on synthetic and
real-world datasets using standard global metrics and the popular Bradley-Terry
model for pairwise comparisons, we found that while global scores provide more
reliable overall rankings, they can underestimate strong models with rare,
significant errors or low confidence. Conversely, pairwise comparisons are
particularly effective for identifying strong contenders among models with
lower global scores, especially where quality metrics are hard to define (e.g.,
text generation), though they require more comparisons to converge if ties are
frequent. Our code and data are available at
https://github.com/HSPyroblast/srw-ranking under a permissive license.",https://github.com/HSPyroblast/srw-ranking,"8 pages, accepted at ACL SRW 2025"
PDFMathTranslate: Scientific Document Translation Preserving Layouts,"Rongxin Ouyang, Chang Chu, Zhikuang Xin, Xiangyao Ma",2025-07-02,2507.03009v2,http://arxiv.org/abs/2507.03009v2,http://arxiv.org/pdf/2507.03009v2,information_retrieval,cs.CL,"Language barriers in scientific documents hinder the diffusion and
development of science and technologies. However, prior efforts in translating
such documents largely overlooked the information in layouts. To bridge the
gap, we introduce PDFMathTranslate, the world's first open-source software for
translating scientific documents while preserving layouts. Leveraging the most
recent advances in large language models and precise layout detection, we
contribute to the community with key improvements in precision, flexibility,
and efficiency. The work has been open-sourced at
https://github.com/byaidu/pdfmathtranslate with more than 222k downloads.",https://github.com/byaidu/pdfmathtranslate,"7 pages, 4 figures"
Uncertainty-Aware Complex Scientific Table Data Extraction,"Kehinde Ajayi, Yi He, Jian Wu",2025-07-02,2507.02009v2,http://arxiv.org/abs/2507.02009v2,http://arxiv.org/pdf/2507.02009v2,information_retrieval,cs.IR,"Table structure recognition (TSR) and optical character recognition (OCR)
play crucial roles in extracting structured data from tables in scientific
documents. However, existing extraction frameworks built on top of TSR and OCR
methods often fail to quantify the uncertainties of extracted results. To
obtain highly accurate data for scientific domains, all extracted data must be
manually verified, which can be time-consuming and labor-intensive. We propose
a framework that performs uncertainty-aware data extraction for complex
scientific tables, built on conformal prediction, a model-agnostic method for
uncertainty quantification (UQ). We explored various uncertainty scoring
methods to aggregate the uncertainties introduced by TSR and OCR. We rigorously
evaluated the framework using a standard benchmark and an in-house dataset
consisting of complex scientific tables in six scientific domains. The results
demonstrate the effectiveness of using UQ for extraction error detection, and
by manually verifying only 47% of extraction results, the data quality can be
improved by 30%. Our work quantitatively demonstrates the role of UQ with the
potential of improving the efficiency in the human-machine cooperation process
to obtain scientifically usable data from complex tables in scientific
documents. All code and data are available on GitHub at
https://github.com/lamps-lab/TSR-OCR-UQ/tree/main.",https://github.com/lamps-lab/TSR-OCR-UQ,
Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System,"Yongsen Zheng, Zongxuan Xie, Guohua Wang, Ziyao Liu, Liang Lin, Kwok-Yan Lam",2025-07-01,2507.02000v1,http://arxiv.org/abs/2507.02000v1,http://arxiv.org/pdf/2507.02000v1,information_retrieval,cs.IR,"Unfairness is a well-known challenge in Recommender Systems (RSs), often
resulting in biased outcomes that disadvantage users or items based on
attributes such as gender, race, age, or popularity. Although some approaches
have started to improve fairness recommendation in offline or static contexts,
the issue of unfairness often exacerbates over time, leading to significant
problems like the Matthew effect, filter bubbles, and echo chambers. To address
these challenges, we proposed a novel framework, Hypergraph Contrastive
Multi-Interest Learning for Fair Conversational Recommender System (HyFairCRS),
aiming to promote multi-interest diversity fairness in dynamic and interactive
Conversational Recommender Systems (CRSs). HyFairCRS first captures a wide
range of user interests by establishing diverse hypergraphs through contrastive
learning. These interests are then utilized in conversations to generate
informative responses and ensure fair item predictions within the dynamic
user-system feedback loop. Experiments on two CRS-based datasets show that
HyFairCRS achieves a new state-of-the-art performance while effectively
alleviating unfairness. Our code is available at
https://github.com/zysensmile/HyFairCRS.",https://github.com/zysensmile/HyFairCRS,
MassTool: A Multi-Task Search-Based Tool Retrieval Framework for Large Language Models,"Jianghao Lin, Xinyuan Wang, Xinyi Dai, Menghui Zhu, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang",2025-07-01,2507.00487v2,http://arxiv.org/abs/2507.00487v2,http://arxiv.org/pdf/2507.00487v2,information_retrieval,cs.IR,"Tool retrieval is a critical component in enabling large language models
(LLMs) to interact effectively with external tools. It aims to precisely filter
the massive tools into a small set of candidates for the downstream
tool-augmented LLMs. However, most existing approaches primarily focus on
optimizing tool representations, often neglecting the importance of precise
query comprehension. To address this gap, we introduce MassTool, a multi-task
search-based framework designed to enhance both query representation and tool
retrieval accuracy. MassTool employs a two-tower architecture: a tool usage
detection tower that predicts the need for function calls, and a tool retrieval
tower that leverages a query-centric graph convolution network (QC-GCN) for
effective query-tool matching. It also incorporates search-based user intent
modeling (SUIM) to handle diverse and out-of-distribution queries, alongside an
adaptive knowledge transfer (AdaKT) module for efficient multi-task learning.
By jointly optimizing tool usage detection loss, list-wise retrieval loss, and
contrastive regularization loss, MassTool establishes a robust dual-step
sequential decision-making pipeline for precise query understanding. Extensive
experiments demonstrate its effectiveness in improving retrieval accuracy. Our
code is available at https://github.com/wxydada/MassTool.",https://github.com/wxydada/MassTool,
Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent,"Haocheng Yu, Yaxiong Wu, Hao Wang, Wei Guo, Yong Liu, Yawen Li, Yuyang Ye, Junping Du, Enhong Chen",2025-06-30,2506.23485v1,http://arxiv.org/abs/2506.23485v1,http://arxiv.org/pdf/2506.23485v1,information_retrieval,cs.CL,"Interactive recommendation is a typical information-seeking task that allows
users to interactively express their needs through natural language and obtain
personalized recommendations. Large language model-powered (LLM-powered) agents
have become a new paradigm in interactive recommendations, effectively
capturing users' real-time needs and enhancing personalized experiences.
However, due to limited planning and generalization capabilities, existing
formulations of LLM-powered interactive recommender agents struggle to
effectively address diverse and complex user intents, such as intuitive,
unrefined, or occasionally ambiguous requests. To tackle this challenge, we
propose a novel thought-augmented interactive recommender agent system (TAIRA)
that addresses complex user intents through distilled thought patterns.
Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring
a manager agent that orchestrates recommendation tasks by decomposing user
needs and planning subtasks, with its planning capacity strengthened through
Thought Pattern Distillation (TPD), a thought-augmentation method that extracts
high-level thoughts from the agent's and human experts' experiences. Moreover,
we designed a set of user simulation schemes to generate personalized queries
of different difficulties and evaluate the recommendations based on specific
datasets. Through comprehensive experiments conducted across multiple datasets,
TAIRA exhibits significantly enhanced performance compared to existing methods.
Notably, TAIRA shows a greater advantage on more challenging tasks while
generalizing effectively on novel tasks, further validating its superiority in
managing complex user intents within interactive recommendation systems. The
code is publicly available at:https://github.com/Alcein/TAIRA.",https://github.com/Alcein/TAIRA,
Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task,"Wuzhenghong Wen, Su Pan, yuwei Sun",2025-06-13,2506.11986v1,http://arxiv.org/abs/2506.11986v1,http://arxiv.org/pdf/2506.11986v1,databases,cs.AI,"Schema linking is a critical step in Text-to-SQL task, aiming to accurately
predict the table names and column names required for the SQL query based on
the given question. However, current fine-tuning approaches for schema linking
models employ a rote-learning paradigm, excessively optimizing for ground truth
schema linking outcomes while compromising reasoning ability. This limitation
arises because of the difficulty in acquiring a high-quality reasoning sample
for downstream tasks. To address this, we propose Schema-R1, a reasoning schema
linking model trained using reinforcement learning. Specifically, Schema-R1
consists of three key steps: constructing small batches of high-quality
reasoning samples, supervised fine-tuning for cold-start initialization, and
rule-based reinforcement learning training. The final results demonstrate that
our method effectively enhances the reasoning ability of the schema linking
model, achieving a 10\% improvement in filter accuracy compared to the existing
method. Our code is available at https://github.com/hongWin/Schema-R1/.",https://github.com/hongWin/Schema-R1,"11 pages, 3 figures, conference"
